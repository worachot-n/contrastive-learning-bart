{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TfGuU-bBsu3J",
    "outputId": "e19cfe61-e01a-4e25-f7d9-d5f86adeedfd",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/worachotn/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/worachotn/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/worachotn/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/worachotn/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "lDTyTH6ysu3O",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()  # Initiate nltk lemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true,
    "id": "BDHK-dEEsu3P",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import pprint\n",
    "import logging\n",
    "\n",
    "import datasets\n",
    "import nltk\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import transformers\n",
    "from accelerate import Accelerator\n",
    "from filelock import FileLock\n",
    "from transformers import AdamW, get_scheduler, set_seed\n",
    "\n",
    "from transformers.file_utils import is_offline_mode\n",
    "from transformers.utils.versions import require_version\n",
    "\n",
    "# from args import parse_args\n",
    "# from data_loader import raw_data_loader, data_processor\n",
    "from model_loader import model_loader\n",
    "from rouge_s import py_rouge_scores\n",
    "from utils import label_smoothed_nll_loss, postprocess_text\n",
    "\n",
    "import json\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from nltk.util import ngrams\n",
    "from nltk import word_tokenize,sent_tokenize\n",
    "\n",
    "import random\n",
    "import utils\n",
    "\n",
    "import datasets\n",
    "from datasets import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import DataCollatorForSeq2Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "dZmO8rfYsu3Q",
    "tags": []
   },
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n",
    "    datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "    level=logging.INFO,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "zI3YKK_psu3Q",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    MODEL_MAPPING,\n",
    "    SchedulerType,\n",
    ")\n",
    "\n",
    "# You should update this to your particular problem to have better documentation of `model_type`\n",
    "MODEL_CONFIG_CLASSES = list(MODEL_MAPPING.keys())\n",
    "MODEL_TYPES = tuple(conf.model_type for conf in MODEL_CONFIG_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AD495S_Dsu3S",
    "outputId": "ac6a6306-5a6b-4f3b-ca58-d8d40e6c20cf",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--gen_negative'], dest='gen_negative', nargs=None, const=None, default=None, type=<class 'bool'>, choices=None, required=False, help='Generate negative topic or not', metavar=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import argparse\n",
    "arg_parser = argparse.ArgumentParser(description=\"BART\")\n",
    "arg_parser.add_argument(\"--len_input\", dest=\"len_input\", type=str, default=None, help=\"set up prefix input\",choices=('no', 'topic', 'length', 'topic-length', 'length-topic', 'simple', 'simple-topic-tagger', 'simple-tagger'))\n",
    "arg_parser.add_argument(\"--len_output\", dest=\"len_output\", default=None, help=\"Use the ctrlen model or not\", choices=('no', 'topic', 'length', 'topic-length', 'length-topic'))\n",
    "arg_parser.add_argument(\"--output_dir\", dest=\"output_dir\", type=str, default=\"./output/1\", help=\"default\")\n",
    "arg_parser.add_argument(\"--train_file\", dest=\"train_file\", type=str, default=None, help=\"A csv or a json file containing the training data.\")\n",
    "arg_parser.add_argument(\"--validation_file\", dest=\"validation_file\", type=str, default=None, help=\"A csv or a json file containing the validation data.\")\n",
    "arg_parser.add_argument(\"--test_file\", dest=\"test_file\", type=str, default=None, help=\"A csv or a json file containing the test data.\")\n",
    "arg_parser.add_argument(\"--ignore_pad_token_for_loss\", dest=\"ignore_pad_token_for_loss\", type=bool, default=True, help=\"Whether to ignore the tokens corresponding to \" \"padded labels in the loss computation or not.\",)\n",
    "arg_parser.add_argument(\"--text_column\", dest=\"text_column\", type=str, default=\"dialogue\", help=\"The name of the column in the datasets containing the full texts (for summarization).\")\n",
    "arg_parser.add_argument(\"--summary_column\", dest=\"summary_column\", type=str, default=\"summary\", help=\"The name of the column in the datasets containing the summaries (for summarization).\")\n",
    "arg_parser.add_argument(\"--model_name_or_path\", dest=\"model_name_or_path\", type=str, default=\"facebook/bart-large\", help=\"Path to pretrained model or model identifier from huggingface.co/models.\")\n",
    "arg_parser.add_argument(\"--model_type\", dest=\"model_type\", type=str, default=\"bart\", help=\"Model type to use if training from scratch.\", choices=MODEL_TYPES)\n",
    "arg_parser.add_argument(\"--max_source_length\", dest=\"max_source_length\", type=int, default=1024, help=\"default\")\n",
    "arg_parser.add_argument(\"--source_prefix\", dest=\"source_prefix\", type=str, default=None, help=\"A prefix to add before every source text \" \"(useful for T5 models).\")\n",
    "arg_parser.add_argument(\"--preprocessing_num_workers\", type=int, default=None, help=\"The number of processes to use for the preprocessing.\")\n",
    "# arg_parser.add_argument(\"--overwrite_cache\", dest=\"overwrite_cache\", type=lambda x:bool(strtobool(x)), default=True, help=\"default\")\n",
    "arg_parser.add_argument(\"--overwrite_cache\", dest=\"overwrite_cache\", type=bool, default=None, help=\"Overwrite the cached training and evaluation sets\")\n",
    "arg_parser.add_argument(\"--min_target_length\", dest=\"min_target_length\", type=int, default=1, help=\"The minimal total sequence length for target text\")\n",
    "arg_parser.add_argument(\"--max_target_length\", dest=\"max_target_length\", type=int, default=128, help=\"The maximum total sequence length for target text after \"\n",
    "        \"tokenization. Sequences longer than this will be truncated, sequences shorter will be padded.\"\n",
    "        \"during ``evaluate`` and ``predict``.\")\n",
    "arg_parser.add_argument(\"--num_beams\", dest=\"num_beams\", type=int, default=4, help=\"Number of beams to use for evaluation. This argument will be \"\n",
    "        \"passed to ``model.generate``, which is used during ``evaluate`` and ``predict``.\")\n",
    "arg_parser.add_argument(\"--learning_rate\", dest=\"learning_rate\", type=float, default=5e-5, help=\"Initial learning rate (after the potential warmup period) to use.\")\n",
    "arg_parser.add_argument(\"--pad_to_max_length\", action=\"store_true\", help=\"If passed, pad all samples to `max_length`. Otherwise, dynamic padding is used.\",)\n",
    "arg_parser.add_argument(\"--weight_decay\", dest=\"weight_decay\", type=float, default=1e-3, help=\"Weight decay to use.\")\n",
    "arg_parser.add_argument(\"--label_smoothing\", dest=\"label_smoothing\", type=float, default=0.1, help=\"hyperparameter for label smoothing.\")\n",
    "arg_parser.add_argument(\"--length_penalty\", dest=\"length_penalty\", type=float, default=1.0, help=\"large - longer sequence, small - shorter sequence\")\n",
    "arg_parser.add_argument(\"--num_train_epochs\", dest=\"num_train_epochs\", type=int, default=15, help=\"Total number of training epochs to perform.\")\n",
    "arg_parser.add_argument(\"--per_device_train_batch_size\", dest=\"per_device_train_batch_size\", type=int, default=8, help=\"Batch size (per device) for the training dataloader.\")\n",
    "arg_parser.add_argument(\"--gradient_accumulation_steps\", dest=\"gradient_accumulation_steps\", type=int, default=64, help=\"Number of updates steps to accumulate before performing a backward/update pass.\")\n",
    "arg_parser.add_argument(\"--per_device_eval_batch_size\", dest=\"per_device_eval_batch_size\", type=int, default=8, help=\"Batch size (per device) for the evaluation dataloader.\")\n",
    "arg_parser.add_argument(\"--per_device_test_batch_size\", dest=\"per_device_test_batch_size\", type=int, default=8, help=\"Batch size (per device) for the evaluation dataloader.\")\n",
    "arg_parser.add_argument(\"--num_warmup_steps\", dest=\"num_warmup_steps\", type=int, default=0, help=\"Number of steps for the warmup in the lr scheduler.\")\n",
    "arg_parser.add_argument(\"--cache_dir\", dest=\"cache_dir\", type=str, default=\"./output/cache\", help=\"default\")\n",
    "arg_parser.add_argument(\"--seed\", dest=\"seed\", type=int, default=12345, help=\"default\")\n",
    "# arg_parser.add_argument(\"-f\", required=False) #important\n",
    "arg_parser.add_argument(\"--config_name\", type=str, default=None, help=\"Pretrained config name or path if not the same as model_name\")\n",
    "arg_parser.add_argument(\"--tokenizer_name\", type=str, default=None, help=\"Pretrained tokenizer name or path if not the same as model_name\")\n",
    "arg_parser.add_argument(\"--use_slow_tokenizer\", dest=\"use_slow_tokenizer\", action=\"store_true\", help=\"If passed, will use a slow tokenizer (not backed by the ðŸ¤— Tokenizers library).\")\n",
    "arg_parser.add_argument(\"--max_train_steps\", type=int, default=None, help=\"Total number of training steps to perform. If provided, overrides num_train_epochs.\")\n",
    "arg_parser.add_argument(\"--lr_scheduler_type\", type=SchedulerType, default=\"linear\", help=\"The scheduler type to use.\", choices=[\"linear\", \"cosine\", \"cosine_with_restarts\", \"polynomial\", \"constant\", \"constant_with_warmup\"])\n",
    "arg_parser.add_argument(\"--ctrlen_model\", action='store_true', default=False, help=\"Use the ctrlen model or not\")\n",
    "arg_parser.add_argument(\"--sim_window_size\", type=int, default=5, help=\"window size for computing loss.\")\n",
    "arg_parser.add_argument(\"--sim_loss\", type=float, default=0, help=\"the loss weight for similarity scores.\")\n",
    "arg_parser.add_argument(\"--special_len_token_init\", type=str, default=None, help=\"ways to initialize special token for length (random, zero, token_embs)\")\n",
    "arg_parser.add_argument(\"--embedding_lr\", type=float, default=5e-5, help=\"Initial learning rate for embedding layers.\")\n",
    "arg_parser.add_argument(\"--len_start\", type=int, default=1, help=\"start length.\")\n",
    "arg_parser.add_argument(\"--len_end\", type=int, default=100, help=\"end length.\")\n",
    "arg_parser.add_argument(\"--data_aug\",action='store_true',default=False,help=\"whether to perform data augmentation or not\")\n",
    "arg_parser.add_argument(\"--pred_len\", action='store_true', default=False, help=\"whether to use the golden length or predicted length\")\n",
    "arg_parser.add_argument(\"--shuffle\", action='store_true', default=False, help=\"whether to shuffle the dataset to balance train/validation/test\")\n",
    "arg_parser.add_argument(\"--debug\", action='store_true', default=False, help=\"Use the debug mode or not\")\n",
    "\n",
    "arg_parser.add_argument(\"--topic_tagger\", dest=\"topic_tagger\", type=bool, default=None, help=\"Use topic tag [TAG] or not\")\n",
    "arg_parser.add_argument(\"--gen_negative\", dest=\"gen_negative\", type=bool, default=None, help=\"Generate negative topic or not\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "sizQFLtFsu3T",
    "tags": []
   },
   "outputs": [],
   "source": [
    "args = arg_parser.parse_args('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "-nJe4mEqsu3U",
    "tags": []
   },
   "outputs": [],
   "source": [
    "args.train_file = \"./data/dialogsum/dialogsum.train.jsonl\"\n",
    "args.validation_file = \"./data/dialogsum/dialogsum.dev.jsonl\"\n",
    "args.test_file = \"./data/dialogsum/dialogsum.test.jsonl\"\n",
    "args.text_column = \"dialogue\"\n",
    "args.summary_column = \"summary\"\n",
    "args.model_name_or_path = \"facebook/bart-large\"\n",
    "args.model_type = \"bart\"\n",
    "args.max_source_length = 1024\n",
    "args.min_target_length = 1\n",
    "args.max_target_length = 128\n",
    "args.num_beams = 4\n",
    "args.learning_rate = 5e-5\n",
    "args.weight_decay = 1e-3\n",
    "args.label_smoothing = 0.1\n",
    "args.length_penalty = 1.0\n",
    "args.num_train_epochs = 5\n",
    "args.per_device_train_batch_size = 2\n",
    "args.gradient_accumulation_steps = 64\n",
    "args.per_device_eval_batch_size = 8\n",
    "args.per_device_test_batch_size = 8\n",
    "args.num_warmup_steps = 0\n",
    "args.cache_dir = \"./output/cache\"\n",
    "args.overwrite_cache = True\n",
    "args.seed = 12345\n",
    "\n",
    "args.len_input = 'topic-length'\n",
    "args.len_output = 'no'\n",
    "args.output_dir = \"./output/1-bart-baseline-loss\"\n",
    "\n",
    "args.topic_tagger = False\n",
    "args.gen_negative = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XOgOOeeYsu3U",
    "outputId": "bea7709d-f0e9-44b8-b4e7-f9a50bde9a46",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic-length\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(args.len_input)\n",
    "print(args.topic_tagger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "i6lyzCTLsu3V",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def simple_tokenize(sentence):\n",
    "    \"\"\" Simple function for tokenizing text with nltk \"\"\"\n",
    "    return nltk.word_tokenize(sentence)\n",
    "\n",
    "def nltk_to_pos(pos):\n",
    "    \"\"\" Simple function for converting nltk pos to wordnet pos\"\"\"\n",
    "    if pos.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif pos.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif pos.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif pos.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    \"\"\" Function to lemmatize text according to the wordnet POS of each token \"\"\"\n",
    "\n",
    "    tokenized_text = nltk.word_tokenize(text)\n",
    "    POS_assigned_text = nltk.pos_tag(tokenized_text)\n",
    "\n",
    "    available_POS = map(lambda x: (x[0], nltk_to_pos(x[1])), POS_assigned_text)\n",
    "\n",
    "    lemmatized_text = [token if pos is None\n",
    "                       else lemmatizer.lemmatize(token, pos)\n",
    "                       for token, pos in available_POS]\n",
    "\n",
    "    return lemmatized_text\n",
    "\n",
    "def build_tagger(original_tokens,lemmatized_tokens, topic_list, idx):\n",
    "    tagged_tokens = []\n",
    "    # Extract all the seed words according to the corresponding topic\n",
    "    token_topics = topic_list\n",
    "    original_list = original_tokens[idx]\n",
    "\n",
    "    for j, token in enumerate(lemmatized_tokens[idx]):\n",
    "        # If the lemmatized form of the token is in topic seeds, tag the original token\n",
    "        if token.lower() in token_topics:\n",
    "            # print(token.lower())\n",
    "            if token.lower() not in stopwords.words('english'):\n",
    "                # print(\"=\"*100)\n",
    "                # print(token.lower())\n",
    "                original_list[j] = '[TAG]' + original_list[j] + '[TAG]'\n",
    "\n",
    "    tagged_tokens.append(\" \".join(original_list))\n",
    "    return tagged_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "s-8h40fYsu3V",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_from_dialogsum(args, file_path):\n",
    "    ''' load dialoguesum jsonl data '''\n",
    "\n",
    "    data = []\n",
    "\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line))\n",
    "    \n",
    "    id_list = [sample['fname'] for sample in data]\n",
    "    dialogue_list = [sample['dialogue'] for sample in data]\n",
    "\n",
    "    if 'summary' in data[0]:\n",
    "        # summary\n",
    "        summary_list = [sample['summary'] for sample in data]\n",
    "        # topic\n",
    "        topic_list = [sample['topic'] for sample in data]\n",
    "\n",
    "    elif 'summary1' in data[0]:\n",
    "\n",
    "        id_list1 = [\"sum1-\"+id for id in id_list]\n",
    "        id_list2 = [\"sum2-\"+id for id in id_list]\n",
    "        id_list3 = [\"sum3-\"+id for id in id_list]\n",
    "\n",
    "        id_list = id_list1 + id_list2 + id_list3\n",
    "        dialogue_list = dialogue_list + dialogue_list + dialogue_list\n",
    "\n",
    "        # summary\n",
    "        summary_list1 = [sample['summary1'] for sample in data]\n",
    "        summary_list2 = [sample['summary2'] for sample in data]\n",
    "        summary_list3 = [sample['summary3'] for sample in data]\n",
    "\n",
    "        summary_list = summary_list1 + summary_list2 + summary_list3\n",
    "\n",
    "        # topic\n",
    "        topic_list1 = [sample['topic1'] for sample in data]\n",
    "        topic_list2 = [sample['topic2'] for sample in data]\n",
    "        topic_list3 = [sample['topic3'] for sample in data]\n",
    "\n",
    "        topic_list = topic_list1 + topic_list2 + topic_list3\n",
    "\n",
    "    if args.topic_tagger:\n",
    "        topic_tagger = []\n",
    "        original_tokens = [simple_tokenize(x) for x in dialogue_list]\n",
    "        lemmatized_tokens = [lemmatize_text(x) for x in dialogue_list]\n",
    "        for i in range(len(lemmatized_tokens)):\n",
    "            tagger = build_tagger(original_tokens, lemmatized_tokens, topic_list[i], i)\n",
    "            topic_tagger.extend(tagger)\n",
    "\n",
    "        data_dict = {'id': id_list,\n",
    "                     'dialogue': topic_tagger,\n",
    "                     'summary': summary_list,\n",
    "                     'topic': topic_list}\n",
    "\n",
    "    if args.gen_negative:\n",
    "        negative_topic = random.sample(topic_list, len(topic_list))\n",
    "        data_dict = {'id': id_list,\n",
    "                     'dialogue': dialogue_list,\n",
    "                     'summary': summary_list,\n",
    "                     'topic': topic_list,\n",
    "                     'negative_topic': negative_topic}\n",
    "\n",
    "\n",
    "    else:\n",
    "        data_dict = {'id': id_list,\n",
    "                     'dialogue': dialogue_list,\n",
    "                     'summary': summary_list,\n",
    "                     'topic': topic_list}\n",
    "\n",
    "    data_dict = Dataset.from_dict(data_dict)\n",
    "\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "qIPnWs3V8onq"
   },
   "outputs": [],
   "source": [
    "def len_adjust(args, split_dict, split_type=None):\n",
    "    ''' add length to the input '''\n",
    "\n",
    "    id_list = split_dict['id']\n",
    "    dialogue_list = split_dict['dialogue']\n",
    "    summary_list = split_dict['summary']\n",
    "    topic_list = split_dict['topic']\n",
    "    negative_topic_list = split_dict['negative_topic']\n",
    "\n",
    "\n",
    "    if args.len_input == 'no':\n",
    "        new_dialogue_list = dialogue_list\n",
    "\n",
    "    # elif args.len_input == 'surface':\n",
    "    #     new_dialogue_list = []\n",
    "    #     for dialogue in dialogue_list:\n",
    "    #         utt_diag = dialogue.split('\\n')\n",
    "    #         num_utt = len(utt_diag)\n",
    "    #         word_diag = [utt.split(' ') for utt in utt_diag]\n",
    "    #         word_diag = [word for utt in word_diag for word in utt]\n",
    "    #         num_word = len(word_diag)\n",
    "\n",
    "    #         new_dialogue = 'Number of utterrance: {}. Length of Dialogue: {}. Dialogue: {}'.format(\n",
    "    #             num_utt, num_word, dialogue)\n",
    "    #         new_dialogue_list.append(new_dialogue)\n",
    "\n",
    "    elif args.len_input == 'length':\n",
    "        new_dialogue_list = []\n",
    "        for dialogue, summary in zip(dialogue_list, summary_list):\n",
    "            sum_len = len(summary.split(' '))\n",
    "            new_dialogue = 'Length of Summary: {}. Dialogue: '.format(\n",
    "                sum_len) + dialogue\n",
    "            new_dialogue_list.append(new_dialogue)\n",
    "\n",
    "    elif args.len_input == 'topic':\n",
    "        new_dialogue_list = []\n",
    "        for dialogue, summary, topic in zip(dialogue_list, summary_list, topic_list):\n",
    "            topic_keyword = topic\n",
    "            new_dialogue = 'Topic of Summary: {}. Dialogue: '.format(\n",
    "                topic_keyword) + dialogue\n",
    "            new_dialogue_list.append(new_dialogue)\n",
    "\n",
    "    elif args.len_input == 'topic-length':\n",
    "        new_dialogue_list = []\n",
    "        negative_dialogue_list = []\n",
    "        for idx, dialogue, summary, topic in zip(id_list, dialogue_list, summary_list, topic_list):\n",
    "            topic_keyword = topic\n",
    "            sum_len = len(summary.split(' '))\n",
    "            if split_type == 'train':\n",
    "                new_dialogue = 'ID: {}</s><s>Topic of Summary: {}. Length of Summary: {}. Dialogue: '.format(\n",
    "                    idx, topic_keyword, sum_len) + dialogue\n",
    "            else:\n",
    "                new_dialogue = 'Topic of Summary: {}. Length of Summary: {}. Dialogue: '.format(\n",
    "                    topic_keyword, sum_len) + dialogue\n",
    "            # negative_dialogue = 'Topic of Summary: {}. Length of Summary: {}. Dialogue: '.format(\n",
    "            #     negative_topic, sum_len) + dialogue\n",
    "            new_dialogue_list.append(new_dialogue)\n",
    "            # negative_dialogue_list.append(negative_dialogue)\n",
    "\n",
    "    elif args.len_input == 'length-topic':\n",
    "        new_dialogue_list = []\n",
    "        for dialogue, summary, topic in zip(dialogue_list, summary_list, topic_list):\n",
    "            topic_keyword = topic\n",
    "            sum_len = len(summary.split(' '))\n",
    "            new_dialogue = 'Length of Summary: {}. Topic of Summary: {}. Dialogue: '.format(\n",
    "                sum_len, topic_keyword) + dialogue\n",
    "            new_dialogue_list.append(new_dialogue)\n",
    "\n",
    "    elif args.len_input == 'simple':\n",
    "        new_dialogue_list = []\n",
    "        for dialogue, summary in zip(dialogue_list, summary_list):\n",
    "            sum_len = len(summary.split(' '))\n",
    "            new_dialogue = 'Summary Length: {}. Dialogue: '.format(\n",
    "                sum_len) + dialogue\n",
    "            new_dialogue_list.append(new_dialogue)\n",
    "\n",
    "    elif args.len_input == 'simple-topic':\n",
    "        new_dialogue_list = []\n",
    "        for dialogue, summary, topic in zip(dialogue_list, summary_list, topic_list):\n",
    "            topic_keyword = topic\n",
    "            sum_len = len(summary.split(' '))\n",
    "            new_dialogue = 'Summary Length: {}. {}. Dialogue: '.format(\n",
    "                sum_len, topic_keyword) + dialogue\n",
    "            new_dialogue_list.append(new_dialogue)\n",
    "\n",
    "    elif args.len_input == 'topic-simple':\n",
    "        new_dialogue_list = []\n",
    "        for dialogue, summary, topic in zip(dialogue_list, summary_list, topic_list):\n",
    "            topic_keyword = topic\n",
    "            sum_len = len(summary.split(' '))\n",
    "            new_dialogue = '{}. Summary Length: {}. Dialogue: '.format(\n",
    "                topic_keyword, sum_len) + dialogue\n",
    "            new_dialogue_list.append(new_dialogue)\n",
    "\n",
    "    elif args.len_input == 'topic-word':\n",
    "        new_dialogue_list = []\n",
    "        for dialogue, summary, topic in zip(dialogue_list, summary_list, topic_list):\n",
    "            topic_keyword = topic\n",
    "            new_dialogue = '{}. Dialogue: '.format(\n",
    "                topic_keyword) + dialogue\n",
    "            new_dialogue_list.append(new_dialogue)\n",
    "\n",
    "    elif args.len_input == 'topic-last-length':\n",
    "        new_dialogue_list = []\n",
    "        for dialogue, summary, topic in zip(dialogue_list, summary_list, topic_list):\n",
    "            topic_keyword = topic\n",
    "            sum_len = len(summary.split(' '))\n",
    "            new_dialogue = 'Topic of Summary: {}. Dialogue: {} Length of Summary: {}'.format(\n",
    "                topic_keyword, dialogue, sum_len)\n",
    "            new_dialogue_list.append(new_dialogue)\n",
    "\n",
    "    if args.len_output == 'no' or split_type == 'val' or split_type == 'test':\n",
    "        new_summary_list = summary_list\n",
    "\n",
    "    elif args.len_output == 'length':\n",
    "        new_summary_list = []\n",
    "        for summary in summary_list:\n",
    "            sum_len = len(summary.split(' '))\n",
    "            new_summary = 'Length of Summary: {}. Summary: '.format(\n",
    "                sum_len) + summary\n",
    "            new_summary_list.append(new_summary)\n",
    "\n",
    "    elif args.len_output == 'topic':\n",
    "        new_summary_list = []\n",
    "        for summary, topic in zip(summary_list, topic_list):\n",
    "            topic_keyword = topic\n",
    "            new_summary = 'Topic of Summary: {}. Summary: '.format(\n",
    "                topic_keyword) + summary\n",
    "            new_summary_list.append(new_summary)\n",
    "\n",
    "    elif args.len_output == 'topic-length':\n",
    "        new_summary_list = []\n",
    "        for summary, topic in zip(summary_list, topic_list):\n",
    "            topic_keyword = topic\n",
    "            sum_len = len(summary.split(' '))\n",
    "            new_summary = 'Topic of Summary: {}. Length of Summary: {}. Summary: '.format(\n",
    "                topic_keyword, sum_len) + summary\n",
    "            new_summary_list.append(new_summary)\n",
    "\n",
    "    elif args.len_output == 'length-topic':\n",
    "        new_summary_list = []\n",
    "        for summary, topic in zip(summary_list, topic_list):\n",
    "            topic_keyword = topic\n",
    "            sum_len = len(summary.split(' '))\n",
    "            new_summary = 'Length of Summary: {}. Topic of Summary: {}. Summary: '.format(\n",
    "                sum_len, topic_keyword) + summary\n",
    "            new_summary_list.append(new_summary)\n",
    "\n",
    "    split_dict = {\n",
    "        'id': id_list,\n",
    "        'dialogue': new_dialogue_list,\n",
    "        'summary': new_summary_list,\n",
    "        'topic': topic_list\n",
    "    }\n",
    "\n",
    "    split_dict = Dataset.from_dict(split_dict)\n",
    "\n",
    "    return split_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "6nlb8t4vsu3W",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def raw_data_loader(args):\n",
    "    ''' load raw datasets from csv files '''\n",
    "\n",
    "    data_files = {}\n",
    "    if args.train_file is not None:\n",
    "        data_files[\"train\"] = args.train_file\n",
    "    if args.validation_file is not None:\n",
    "        data_files[\"validation\"] = args.validation_file\n",
    "    if args.test_file is not None:\n",
    "        data_files[\"test\"] = args.test_file\n",
    "\n",
    "    if 'dialogsum' in args.train_file:\n",
    "        train_dict = load_from_dialogsum(args, args.train_file)\n",
    "        val_dict   = load_from_dialogsum(args, args.validation_file)\n",
    "        test_dict  = load_from_dialogsum(args, args.test_file)\n",
    "\n",
    "    # train_dict = utils.len_adjust(args, train_dict, 'train')\n",
    "    # val_dict   = utils.len_adjust(args, val_dict, 'val')\n",
    "    # test_dict  = utils.len_adjust(args, test_dict, 'test')\n",
    "    train_dict = len_adjust(args, train_dict, 'train')\n",
    "    val_dict   = len_adjust(args, val_dict, 'val')\n",
    "    test_dict  = len_adjust(args, test_dict, 'test')\n",
    "\n",
    "    raw_datasets = datasets.DatasetDict({\"train\":train_dict, \"validation\":val_dict, \"test\":test_dict})\n",
    "\n",
    "    return raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w9inHWSWsu3W",
    "outputId": "45b052ae-b1e0-402e-b7e1-3fd66619601c",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary', 'topic'],\n",
       "        num_rows: 12460\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary', 'topic'],\n",
       "        num_rows: 500\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary', 'topic'],\n",
       "        num_rows: 1500\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dialogsum = raw_data_loader(args)\n",
    "dialogsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "tz2ZuJAMsu3X",
    "tags": []
   },
   "outputs": [],
   "source": [
    "raw_datasets = raw_data_loader(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hXOyCtjYvQUH",
    "outputId": "f15f305c-71b5-4c0f-adc7-074cad71fee8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary', 'topic'],\n",
       "        num_rows: 12460\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary', 'topic'],\n",
       "        num_rows: 500\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary', 'topic'],\n",
       "        num_rows: 1500\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8LVH7c2csu3X",
    "outputId": "df3ae011-014b-437e-a6ab-8d285a7c979c",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10/14/2023 14:18:14 - INFO - __main__ - Distributed environment: NO\n",
      "Num processes: 1\n",
      "Process index: 0\n",
      "Local process index: 0\n",
      "Device: cuda\n",
      "\n",
      "Mixed precision type: fp16\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accelerator = Accelerator(mixed_precision=\"fp16\")\n",
    "logger.info(accelerator.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "JrjSjmUssu3Y",
    "tags": []
   },
   "outputs": [],
   "source": [
    "logger.setLevel(logging.INFO if accelerator.is_local_main_process else logging.ERROR)\n",
    "accelerator.is_local_main_process\n",
    "datasets.utils.logging.set_verbosity_warning()\n",
    "transformers.utils.logging.set_verbosity_info()\n",
    "set_seed(args.seed)\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "accelerator.is_main_process\n",
    "os.makedirs(args.output_dir, exist_ok=True)\n",
    "accelerator.wait_for_everyone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9y_Gspbqsu3Y",
    "outputId": "aac050f9-7369-4b98-f0fa-343cfa962896",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at ./output/cache/models--facebook--bart-large/snapshots/cb48c1365bd826bd521f650dc2e0940aee54720c/config.json\n",
      "Model config BartConfig {\n",
      "  \"_name_or_path\": \"facebook/bart-large\",\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.1,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 12,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 16,\n",
      "  \"encoder_ffn_dim\": 4096,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 12,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": false,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 128,\n",
      "      \"min_length\": 12,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_cnn\": {\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 142,\n",
      "      \"min_length\": 56,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_xsum\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 62,\n",
      "      \"min_length\": 11,\n",
      "      \"num_beams\": 6\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.34.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at ./output/cache/models--facebook--bart-large/snapshots/cb48c1365bd826bd521f650dc2e0940aee54720c/config.json\n",
      "Model config BartConfig {\n",
      "  \"_name_or_path\": \"facebook/bart-large\",\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.1,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 12,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 16,\n",
      "  \"encoder_ffn_dim\": 4096,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 12,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": false,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 128,\n",
      "      \"min_length\": 12,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_cnn\": {\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 142,\n",
      "      \"min_length\": 56,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_xsum\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 62,\n",
      "      \"min_length\": 11,\n",
      "      \"num_beams\": 6\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.34.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading file vocab.json from cache at ./output/cache/models--facebook--bart-large/snapshots/cb48c1365bd826bd521f650dc2e0940aee54720c/vocab.json\n",
      "loading file merges.txt from cache at ./output/cache/models--facebook--bart-large/snapshots/cb48c1365bd826bd521f650dc2e0940aee54720c/merges.txt\n",
      "loading file tokenizer.json from cache at ./output/cache/models--facebook--bart-large/snapshots/cb48c1365bd826bd521f650dc2e0940aee54720c/tokenizer.json\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at ./output/cache/models--facebook--bart-large/snapshots/cb48c1365bd826bd521f650dc2e0940aee54720c/tokenizer_config.json\n",
      "loading configuration file config.json from cache at ./output/cache/models--facebook--bart-large/snapshots/cb48c1365bd826bd521f650dc2e0940aee54720c/config.json\n",
      "Model config BartConfig {\n",
      "  \"_name_or_path\": \"facebook/bart-large\",\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.1,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 12,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 16,\n",
      "  \"encoder_ffn_dim\": 4096,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 12,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": false,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 128,\n",
      "      \"min_length\": 12,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_cnn\": {\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 142,\n",
      "      \"min_length\": 56,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_xsum\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 62,\n",
      "      \"min_length\": 11,\n",
      "      \"num_beams\": 6\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.34.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at ./output/cache/models--facebook--bart-large/snapshots/cb48c1365bd826bd521f650dc2e0940aee54720c/pytorch_model.bin\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1\n",
      "}\n",
      "\n",
      "All model checkpoint weights were used when initializing BartForConditionalGeneration.\n",
      "\n",
      "All the weights of BartForConditionalGeneration were initialized from the model checkpoint at facebook/bart-large.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BartForConditionalGeneration for predictions without further training.\n",
      "Generation config file not found, using a generation config created from the model config.\n",
      "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 50265. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n",
      "Configuration saved in ./output/1-bart-baseline-loss/start/config.json\n",
      "Configuration saved in ./output/1-bart-baseline-loss/start/generation_config.json\n",
      "Model weights saved in ./output/1-bart-baseline-loss/start/pytorch_model.bin\n",
      "tokenizer config file saved in ./output/1-bart-baseline-loss/start/tokenizer_config.json\n",
      "Special tokens file saved in ./output/1-bart-baseline-loss/start/special_tokens_map.json\n"
     ]
    }
   ],
   "source": [
    "config, tokenizer, model = model_loader(accelerator, logger, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "II9gKXJfsu3X",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def data_processor(logger, args, accelerator, raw_datasets, tokenizer, model):\n",
    "    ''' prepare dataset format for train/val/test '''\n",
    "    def preprocess_function(examples):\n",
    "\n",
    "        # summary - target\n",
    "        targets = examples[summary_column]\n",
    "        with tokenizer.as_target_tokenizer():\n",
    "            labels = tokenizer(targets, max_length=max_target_length, padding=padding, truncation=True)\n",
    "\n",
    "        if args.ctrlen_model:\n",
    "            gold_sum_len = [len(item) for item in labels['attention_mask']]\n",
    "\n",
    "        # dialogue - input\n",
    "        inputs = examples[text_column]\n",
    "        new_inputs = []\n",
    "        for i, inp in enumerate(inputs):\n",
    "            if args.ctrlen_model:\n",
    "                if 'pred_len' in examples:\n",
    "                    new_inputs.append(prefix + \"<len_{}> \".format(examples['pred_len'][i]) + inp)\n",
    "\n",
    "                else:\n",
    "                    new_inputs.append(prefix + \"<len_{}> \".format(gold_sum_len[i]) + inp)\n",
    "            else:\n",
    "                new_inputs.append(prefix + inp)\n",
    "\n",
    "        inputs = new_inputs\n",
    "        # id = examples['id']\n",
    "        # new_id = [x.split(\"_\")[1] for x in id]\n",
    "        # print(new_id)\n",
    "        # print(type(new_id))\n",
    "        # negative_dialogue = examples['negative_dialogue']\n",
    "        model_inputs = tokenizer(inputs, max_length=args.max_source_length, padding=padding, truncation=True)\n",
    "        # negative_inputs = tokenizer(inputs, max_length=args.max_source_length, padding=padding, truncation=True)\n",
    "        # negative_inputs = tokenizer(negative_dialogue, max_length=args.max_source_length, padding=padding, truncation=True)\n",
    "        # print(model_inputs)\n",
    "        # print(len(model_inputs['input_ids'][0]))\n",
    "        # print(len(negative_inputs['input_ids'][0]))\n",
    "        # print(len(model_inputs['attention_mask']))\n",
    "\n",
    "        # If we are padding here, replace all tokenizer.pad_token_id in the labels by -100 when we want to ignore\n",
    "        # padding in the loss.\n",
    "        if padding == \"max_length\" and args.ignore_pad_token_for_loss:\n",
    "            labels[\"input_ids\"] = [\n",
    "                [(l if l != tokenizer.pad_token_id else -100) for l in label] for label in labels[\"input_ids\"]\n",
    "            ]\n",
    "\n",
    "        # model_inputs['neg_input_ids'] = negative_inputs['input_ids']\n",
    "        # model_inputs['neg_attention_mask'] = negative_inputs['attention_mask']\n",
    "        # model_inputs[\"id\"] = new_id\n",
    "        # print(type(labels[\"input_ids\"]))\n",
    "        model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "\n",
    "        if args.ctrlen_model:\n",
    "            model_inputs[\"gold_len\"] = gold_sum_len\n",
    "\n",
    "        return model_inputs\n",
    "\n",
    "    prefix = args.source_prefix if args.source_prefix is not None else \"\"\n",
    "\n",
    "    # Preprocessing the datasets.\n",
    "    # First we tokenize all the texts.\n",
    "    column_names = raw_datasets[\"train\"].column_names\n",
    "\n",
    "    # Get the column names for input/target.\n",
    "    text_column = args.text_column\n",
    "    if text_column not in column_names:\n",
    "        raise ValueError(\n",
    "            f\"--text_column' value '{args.text_column}' needs to be one of: {', '.join(column_names)}\"\n",
    "        )\n",
    "\n",
    "    summary_column = args.summary_column\n",
    "    if summary_column not in column_names:\n",
    "        raise ValueError(\n",
    "            f\"--summary_column' value '{args.summary_column}' needs to be one of: {', '.join(column_names)}\"\n",
    "        )\n",
    "\n",
    "    # Temporarily set max_target_length for training.\n",
    "    max_target_length = args.max_target_length\n",
    "    padding = \"max_length\" if args.pad_to_max_length else False\n",
    "\n",
    "\n",
    "\n",
    "    with accelerator.main_process_first():\n",
    "        processed_datasets = raw_datasets.map(\n",
    "            preprocess_function,\n",
    "            batched=True,\n",
    "            batch_size=1000,\n",
    "            remove_columns=column_names,\n",
    "            load_from_cache_file=not args.overwrite_cache,\n",
    "            desc=\"Running tokenizer on dataset\",\n",
    "        )\n",
    "\n",
    "    train_dataset = processed_datasets[\"train\"]\n",
    "    eval_dataset  = processed_datasets[\"validation\"]\n",
    "    test_dataset  = processed_datasets[\"test\"]\n",
    "\n",
    "    # Log a few random samples from the training set:\n",
    "    for index in random.sample(range(len(train_dataset)), 1):\n",
    "        logger.info(f\"Sample {index} of the training set: {train_dataset[index]}.\")\n",
    "\n",
    "    label_pad_token_id = -100 if args.ignore_pad_token_for_loss else tokenizer.pad_token_id\n",
    "    data_collator = DataCollatorForSeq2Seq(\n",
    "        tokenizer,\n",
    "        model=model,\n",
    "        label_pad_token_id=label_pad_token_id,\n",
    "        pad_to_multiple_of=8 if accelerator.use_fp16 else None,\n",
    "    )\n",
    "\n",
    "    # data_collator = CustomDataCollatorForSeq2Seq(        \n",
    "    #     tokenizer,\n",
    "    #     model=model,\n",
    "    #     label_pad_token_id=label_pad_token_id,\n",
    "    #     pad_to_multiple_of=8 if accelerator.use_fp16 else None,\n",
    "    #     # padding='do_not_pad'\n",
    "    # )\n",
    "\n",
    "    train_dataloader = DataLoader(train_dataset, shuffle=True, collate_fn=data_collator, batch_size=args.per_device_train_batch_size)\n",
    "    eval_dataloader = DataLoader(eval_dataset, collate_fn=data_collator, batch_size=args.per_device_eval_batch_size)\n",
    "    test_dataloader = DataLoader(test_dataset, collate_fn=data_collator, batch_size=args.per_device_test_batch_size)\n",
    "\n",
    "    return (train_dataloader, eval_dataloader, test_dataloader), (train_dataset, eval_dataset, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 220,
     "referenced_widgets": [
      "d0098c03b82d48c9acdc684fbbf54567",
      "fa32d34f467944f2aaf4a13fdf7a0cf2",
      "e3bc145889c94fc3974e88e46863db89",
      "ddbc6421b4cf487d92cc53fb0ae6f634",
      "13bb8c4b9a154bb99c4d38cd2edb631c",
      "5a2947306125452c8c25c12e54dc6656",
      "326356876bd540778d188c41673e04f5",
      "542a00a050384f5f8f3f7354eb527336",
      "a91a8c5870234ab3bdd0132addb34a20",
      "9c182b108efa471994186923f10871a8",
      "c34934bec45646a8b2ac76c60dc124d5",
      "24272444846441638d4836fd835562dc",
      "78f6c1bca77640ca92bd87d5995fced5",
      "81669ba2443a489cb535c508333dc974",
      "47ddb2c2d8fa4c278c9d514ace68341f",
      "b842e08bc1ca45ee99a868d1dfa4d0db",
      "4616558f0ebd466babad0202bc55824d",
      "9a4ed651601f4a29b763eed10afafc16",
      "368a820467ad4f4d8198932125f0d357",
      "f5ece15e08e44905a09d9a2e988a4be4",
      "932e4629e7f340c2a5b64d095c46bf4d",
      "a26c7dc74d71494787fd32d560594b38",
      "90b25ecb208546f9938652c360ef7a5e",
      "852ba2b2a4fd4bbe80a2ecd9c9f6b5fb",
      "7f1272db213a4121ae95b5e41061d964",
      "a3ad3e93702041d89b6f505ec6d37411",
      "ffcb842d99954cdcaa8fb78e8e3b2215",
      "b1a15a93c5e746888806f8dd19cf6889",
      "35f50d433dc14aa28cf0f5a039f7cb87",
      "e69f5057741b46dba3ebb186ef85c6db",
      "14052c5abfad4231a0d4c8d0e0395a01",
      "3bad8094e9124ab391d945edf4ccca2f",
      "31409e259c8b4ee7899035ea4ba3f140"
     ]
    },
    "id": "BNku9V-ssu3Y",
    "outputId": "ab678f18-5bfa-4b54-fbb4-cac959f8edcb",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74389a3f8e0340df89f7995125bb13b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/12460 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/worachotn/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3864: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0617191f2f954a948c135e41e55dd699",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "207aa226cced40e58d95109f8846882d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/1500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10/14/2023 14:18:45 - INFO - __main__ - Sample 6825 of the training set: {'input_ids': [0, 2688, 35, 2341, 1215, 4671, 1244, 2, 0, 48931, 9, 19584, 35, 1207, 317, 4, 41852, 9, 19584, 35, 290, 4, 33854, 35, 849, 41761, 134, 10431, 35, 6233, 110, 284, 3033, 259, 13, 251, 116, 50118, 10431, 41761, 176, 10431, 35, 4934, 8, 10, 457, 107, 4, 166, 1410, 259, 15, 5, 78, 9, 759, 4, 50118, 10431, 41761, 134, 10431, 35, 370, 33, 10, 5500, 1217, 4, 50118, 10431, 41761, 176, 10431, 35, 3216, 4, 38, 657, 1207, 259, 4, 50118, 10431, 41761, 134, 10431, 35, 6893, 328, 370, 64, 192, 5, 3375, 169, 159, 11, 5, 15044, 4, 50118, 10431, 41761, 176, 10431, 35, 3216, 4, 85, 18, 10, 9869, 1217, 4, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [0, 10431, 41761, 176, 10431, 1074, 259, 8, 11952, 10, 205, 1217, 4, 2]}.\n",
      "/home/worachotn/.local/lib/python3.10/site-packages/accelerate/accelerator.py:523: FutureWarning: The `use_fp16` property is deprecated and will be removed in version 1.0 of Accelerate use `Accelerator.mixed_precision == 'fp16'` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "dataloader, processed_dataset = data_processor(logger, args, accelerator, raw_datasets, tokenizer, model)\n",
    "train_dataloader, eval_dataloader, test_dataloader = dataloader\n",
    "train_dataset, _, _ = processed_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HD4JVgBRFOlA",
    "outputId": "8915a69c-5801-4da1-9053-00859e286af5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 12460\n",
       "})"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset['id'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RHvfVGcQvhIC",
    "outputId": "654ee714-48ee-4e49-cdb2-2a8cf6edbe0d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7f73eae04e50>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BartTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,  2688,    35,  2341,  1215,  4718,  6478,     2,     0, 48931,\n",
      "             9, 19584,    35,    71,    12,    29,  4575,   544,     4, 41852,\n",
      "             9, 19584,    35,   753,     4, 33854,    35,   849, 41761,   134,\n",
      "         10431,    35, 22847,  3698,   162,     6,    38,  2162,    42, 23204,\n",
      "          2350,     4,   125,    77,    38,   300,   184,     8,  1381,    24,\n",
      "            15,     6,    38,   303,    24,    18,   350,   650,     4, 50118,\n",
      "         10431, 41761,   176, 10431,    35,  1832,    47,    33,     5, 18245,\n",
      "            19,    47,   116, 50118, 10431, 41761,   134, 10431,    35,  3216,\n",
      "             6,   259,    47,    32,     4, 50118, 10431, 41761,   176, 10431,\n",
      "            35,  3837,    47,     4,  1832,    47,   236,   110,   418,   124,\n",
      "           116, 50118, 10431, 41761,   134, 10431,    35,   440,     6,    64,\n",
      "            38,  2081,    24,    13,    10,  2671,    65,   116, 50118, 10431,\n",
      "         41761,   176, 10431,    35,    38,   524,  6023,    42,    16,     5,\n",
      "           934,  1836,    52,    33,     4, 50118, 10431, 41761,   134, 10431,\n",
      "            35,  5534,     6,    14,    18,   350,  1099,     4, 50118, 10431,\n",
      "         41761,   176, 10431,    35,  5359,    47,    74,   101,     7,   860,\n",
      "            42,    65,    19,     5,    40,  1722,  6184,     4,    20,   425,\n",
      "            16,     5,   276,     8,    24,    18,  2671,     4,     2,     1,\n",
      "             1,     1,     1,     1],\n",
      "        [    0,  2688,    35,  2341,  1215,  3305,  2022,     2,     0, 48931,\n",
      "             9, 19584,    35,  2317,    86,     4, 41852,     9, 19584,    35,\n",
      "           601,     4, 33854,    35,   849, 41761,   134, 10431,    35, 21893,\n",
      "          1493,   116, 50118, 10431, 41761,   176, 10431,    35,  3216,     6,\n",
      "            65,    94,   631,     4,  1336,   203,  2317,    86,   109,    47,\n",
      "           492,   110,  1321,   358,    76,   116, 50118, 10431, 41761,   134,\n",
      "         10431,    35,  1541,  1321,  1325,   379,   360,     9,  1199,  7196,\n",
      "           358,    76,     4,   318,    47,   218,    75,   304,     5,   455,\n",
      "           379,   360,     6,    51,  2324,    81,     7,     5,   511,    76,\n",
      "             4, 50118, 10431, 41761,   176, 10431,    35,  1336,    59,  4736,\n",
      "           360,   116, 50118, 10431, 41761,   134, 10431,    35,   370,   120,\n",
      "           195,  1199,  4736,   360,     4, 50118, 10431, 41761,   176, 10431,\n",
      "            35,  5053,    97,  1795,   116, 50118, 10431, 41761,   134, 10431,\n",
      "            35,  3216,     6,    52,    33,    41,  4206,  3832,   563,     8,\n",
      "          1131,  1911,    25,   157,     4, 50118, 10431, 41761,   176, 10431,\n",
      "            35,  2860,     4,  4557,    98,   203,    13,   110,    86,     4,\n",
      "         50118, 10431, 41761,   134, 10431,    35,   166,   581,  1511,    47,\n",
      "          1010,     6,  1560,     4,  4557,    13,   567,    11,     4,     2,\n",
      "             1,     1,     1,     1]])\n",
      "[\"<s>ID: train_7793</s><s>Topic of Summary: after-sales service. Length of Summary: 19. Dialogue: #Person1#: Excuse me, I bought this sweater yesterday. But when I got home and tried it on, I found it's too small.\\n#Person2#: Do you have the receipt with you?\\n#Person1#: Yes, here you are.\\n#Person2#: Thank you. Do you want your money back?\\n#Person1#: No, can I exchange it for a bigger one?\\n#Person2#: I am afraid this is the biggest size we have.\\n#Person1#: Oh, that's too bad.\\n#Person2#: Maybe you would like to try this one with the willow pattern. The price is the same and it's bigger.</s><pad><pad><pad><pad><pad>\", \"<s>ID: train_4435</s><s>Topic of Summary: holiday time. Length of Summary: 17. Dialogue: #Person1#: Anything else?\\n#Person2#: Yes, one last thing. How much holiday time do you give your employees every year?\\n#Person1#: Our employees receive 15 days of paid vacation every year. If you don't use the full 15 days, they carry over to the following year.\\n#Person2#: How about sick days?\\n#Person1#: You get 5 paid sick days.\\n#Person2#: Any other benefits?\\n#Person1#: Yes, we have an excellent retirement plan and medical insurance as well.\\n#Person2#: Great. Thanks so much for your time.\\n#Person1#: We'll contact you soon, Tom. Thanks for coming in.</s><pad><pad><pad><pad>\"]\n"
     ]
    }
   ],
   "source": [
    "for step, batch in enumerate(train_dataloader):\n",
    "    # print(tokenizer.decode(batch['input_ids'][0]))\n",
    "    print(batch.input_ids)\n",
    "    print(tokenizer.batch_decode(batch.input_ids))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n3z17N4Jsu3Y",
    "outputId": "1849c4bf-2915-4771-b728-98c0e23ab664",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/worachotn/.local/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# = = = Training Preparation = = =\n",
    "# Optimizer\n",
    "# Split weights in two groups, one with weight decay and the other not.\n",
    "no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "\n",
    "if args.ctrlen_model:\n",
    "    no_decay_emb_matrix = [\"bias\", \"LayerNorm.weight\", \"shared\"]\n",
    "else:\n",
    "    no_decay_emb_matrix = [\"bias\", \"LayerNorm.weight\"]\n",
    "\n",
    "optimizer_grouped_parameters = [\n",
    "    {\n",
    "        \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay_emb_matrix)],\n",
    "        \"weight_decay\": args.weight_decay,\n",
    "    },\n",
    "    {\n",
    "        \"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "        \"weight_decay\": 0.0,\n",
    "    },\n",
    "]\n",
    "\n",
    "if args.ctrlen_model:\n",
    "    if args.model_type == 'bart':\n",
    "        optimizer_grouped_parameters.extend([{\n",
    "            \"params\": model.seq2seq_model.model.shared.parameters(),\n",
    "            \"lr\": args.embedding_lr}])\n",
    "    elif args.model_type == 't5':\n",
    "        optimizer_grouped_parameters.extend([{\n",
    "            \"params\": model.seq2seq_model.shared.parameters(),\n",
    "            \"lr\": args.embedding_lr}])\n",
    "    else:\n",
    "        raise ValueError('{} model type not implemented'.format(args.model_type))\n",
    "\n",
    "# optimizer\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=args.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "id": "B9dY-SZEsu3Z",
    "tags": []
   },
   "outputs": [],
   "source": [
    "model, optimizer, train_dataloader, eval_dataloader, test_dataloader = accelerator.prepare(\n",
    "    model, optimizer, train_dataloader, eval_dataloader, test_dataloader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "4b15de89357c428997a59f4e22166ad3"
     ]
    },
    "id": "JBQUGWIqsu3Z",
    "outputId": "062bdecd-ceb2-484a-ab79-13750ecfc0b7",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10/14/2023 14:18:46 - INFO - __main__ - ***** Running training *****\n",
      "10/14/2023 14:18:46 - INFO - __main__ -  Num examples = 12460\n",
      "10/14/2023 14:18:46 - INFO - __main__ -  Num Epochs = 5\n",
      "10/14/2023 14:18:46 - INFO - __main__ -  Instantaneous batch size per device = 2\n",
      "10/14/2023 14:18:46 - INFO - __main__ -  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "10/14/2023 14:18:46 - INFO - __main__ -  Gradient Accumulation steps = 64\n",
      "10/14/2023 14:18:46 - INFO - __main__ -  Total optimization steps = 490\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2679ba301024472a186cd00e991d483",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/490 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Scheduler and math around the number of training steps.\n",
    "num_update_steps_per_epoch = math.ceil(len(train_dataloader) / args.gradient_accumulation_steps)\n",
    "if args.max_train_steps is None:\n",
    "    args.max_train_steps = args.num_train_epochs * num_update_steps_per_epoch\n",
    "else:\n",
    "    args.num_train_epochs = math.ceil(args.max_train_steps / num_update_steps_per_epoch)\n",
    "\n",
    "lr_scheduler = get_scheduler(\n",
    "    name=args.lr_scheduler_type,\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=args.num_warmup_steps,\n",
    "    num_training_steps=args.max_train_steps,\n",
    ")\n",
    "\n",
    "# = = = = = = = = = = = = = = = = Train = = = = = = = = = = = = = = = = = = =\n",
    "total_batch_size = args.per_device_train_batch_size * accelerator.num_processes * args.gradient_accumulation_steps\n",
    "\n",
    "logger.info(\"***** Running training *****\")\n",
    "logger.info(f\" Num examples = {len(train_dataset)}\")\n",
    "logger.info(f\" Num Epochs = {args.num_train_epochs}\")\n",
    "logger.info(f\" Instantaneous batch size per device = {args.per_device_train_batch_size}\")\n",
    "logger.info(f\" Total train batch size (w. parallel, distributed & accumulation) = {total_batch_size}\")\n",
    "logger.info(f\" Gradient Accumulation steps = {args.gradient_accumulation_steps}\")\n",
    "logger.info(f\" Total optimization steps = {args.max_train_steps}\")\n",
    "\n",
    "# Only show the progress bar once on each machine.\n",
    "progress_bar = tqdm(range(args.max_train_steps), desc=\"Training: \", disable=not accelerator.is_local_main_process)\n",
    "completed_steps = 0\n",
    "\n",
    "val_results = []\n",
    "acc_losses  = []\n",
    "best_r2_f1  = None\n",
    "best_epoch  = 0\n",
    "\n",
    "if args.model_type == 'bart' or args.model_type == 't5':\n",
    "    task_specific_params = model.config.task_specific_params\n",
    "    params = task_specific_params.get('summarization', {})\n",
    "    params['min_length'] = args.min_target_length\n",
    "    params['max_length'] = args.max_target_length\n",
    "    params['length_penalty'] = args.length_penalty\n",
    "    params['num_beams'] = args.num_beams\n",
    "    model.config.update(params)\n",
    "else:\n",
    "    raise ValueError('{} model type not implemented'.format(args.model_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    " \n",
    "# Opening JSON file\n",
    "f = open('negative_pair.json')\n",
    " \n",
    "# returns JSON object as \n",
    "# a dictionary\n",
    "data = json.load(f)\n",
    "\n",
    "# Closing file\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Topic of Summary: see a doctor. Length of Summary: 18. Dialogue: #Person1#: Hello, how are you doing today?\\n#Person2#: I ' Ve been having trouble breathing lately.\\n#Person1#: Have you had any type of cold lately?\\n#Person2#: No, I haven ' t had a cold. I just have a heavy feeling in my chest when I try to breathe.\\n#Person1#: Do you have any allergies that you know of?\\n#Person2#: No, I don ' t have any allergies that I know of.\\n#Person1#: Does this happen all the time or mostly when you are active?\\n#Person2#: It happens a lot when I work out.\\n#Person1#: I am going to send you to a pulmonary specialist who can run tests on you for asthma.\\n#Person2#: Thank you for your help, doctor.\""
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets['validation']['dialogue'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'attention_mask', 'labels', 'decoder_input_ids'])\n",
      "tensor([[    0, 33184,   373, 11450,    53, 11450,   399,    75, 10418,   142,\n",
      "            79,    21,  2053,    59,     5,  1703,  3213,    79,  6957,     4,\n",
      "          5031,  6990,    59,     5, 12675,     8,    54,   197,   185,     5,\n",
      "          2640,     4,     2,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100],\n",
      "        [    0, 10431, 41761,   134, 10431,     8,   849, 41761,   176, 10431,\n",
      "          8654,    81,     5,  1254,     9,    49,   721,     6,   217,     5,\n",
      "          6720,     6,     5,  1911,  3154,     6,     5,  4240,  4029,     6,\n",
      "          4753,     4,   252,  1338,    41,  1288,    23,     5,   253,     4,\n",
      "             2,  -100,  -100,  -100,  -100,  -100,  -100,  -100]],\n",
      "       device='cuda:0')\n",
      "tensor([[    2,     0, 33184,   373, 11450,    53, 11450,   399,    75, 10418,\n",
      "           142,    79,    21,  2053,    59,     5,  1703,  3213,    79,  6957,\n",
      "             4,  5031,  6990,    59,     5, 12675,     8,    54,   197,   185,\n",
      "             5,  2640,     4,     2,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    2,     0, 10431, 41761,   134, 10431,     8,   849, 41761,   176,\n",
      "         10431,  8654,    81,     5,  1254,     9,    49,   721,     6,   217,\n",
      "             5,  6720,     6,     5,  1911,  3154,     6,     5,  4240,  4029,\n",
      "             6,  4753,     4,   252,  1338,    41,  1288,    23,     5,   253,\n",
      "             4,     2,     1,     1,     1,     1,     1,     1]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for step, batch in enumerate(train_dataloader):\n",
    "    # print(tokenizer.decode(batch['input_ids'][0]))\n",
    "    print(batch.keys())\n",
    "    print(batch.labels)\n",
    "    print(batch.decoder_input_ids)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "c93c25e40e054458b7dfbd865069cadd"
     ]
    },
    "id": "awYeoAgOsu3Z",
    "outputId": "332daa87-c3c6-4fef-edcb-0e5124a48f23",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10/14/2023 14:24:49 - INFO - __main__ - ***** Running training *****\n",
      "10/14/2023 14:24:49 - INFO - __main__ -  Num examples = 12460\n",
      "10/14/2023 14:24:49 - INFO - __main__ -  Num Epochs = 5\n",
      "10/14/2023 14:24:49 - INFO - __main__ -  Instantaneous batch size per device = 2\n",
      "10/14/2023 14:24:49 - INFO - __main__ -  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "10/14/2023 14:24:49 - INFO - __main__ -  Gradient Accumulation steps = 64\n",
      "10/14/2023 14:24:49 - INFO - __main__ -  Total optimization steps = 490\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29d02cd409dd4e0e863a92d08f55bf6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/490 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7, device='cuda:0')\n",
      "Part 1: tensor([    0,  2688,    35,  2341,  1215, 33626,   134,     2],\n",
      "       device='cuda:0')\n",
      "Part 2: tensor([    0, 48931,     9, 19584,    35,    10,  2602,   985,     4, 41852,\n",
      "            9, 19584,    35,   974,     4, 33854,    35,   849, 41761,   134,\n",
      "        10431,    35,    38,   437,  1686,     7, 12585,  2610,     6,    54,\n",
      "           16,    10,   182,  2602,   985,     4,  1405,  1354,   384,   352,\n",
      "        11409,     6,  1382,    15,     5,  1289,     9,   928, 18612, 22131,\n",
      "        10112,    11,     5,  4388,     6,     5,  8479,     9,  3920,    94,\n",
      "          353,     4,   407,   141,   222,    24,    70,   283,    59,   116,\n",
      "        50118, 10431, 41761,   176, 10431,    35,  2647,     6,   454,    94,\n",
      "           76,     6,     5,  1114,     9,    69,  8165,    23,     5,   928,\n",
      "        18612, 22131,    74,    33,    57, 29824,    13,    84,   284,     4,\n",
      "         6828,   554,     7,  1369,    77, 11924,   300,     5,   981,   774,\n",
      "           13,     5,   311, 17739,    23,     5,   400,  7364,     4,   286,\n",
      "        17739,     6, 11924,    56,     7,  1532,    55,    87,  1878,  2301,\n",
      "            4,   264,    21,    15,  1289,    31,   144,     9,     5,   132,\n",
      "          722,   311,     4,    38,  1276,    14,    52,   109,   158,  6052,\n",
      "           10,   363,     4,   572, 16617,  2787,    24,     6,    38,   851,\n",
      "           69,    10,   516,     8,    79,    74,    33,     7,  1137,   162,\n",
      "           99,     5,   220,   516,    21,     4,   264,  2738,    24,    70,\n",
      "           62,   190,   357,    87,    69, 19122,     4, 50118, 10431, 41761,\n",
      "          134, 10431,    35,   178,    79,   222,   157,    11,     5,   233,\n",
      "            4, 50118, 10431, 41761,   176, 10431,    35,   264,    21,   372,\n",
      "           11,     5,   233,     4,   264,    56,   460,    57,  9152,     8,\n",
      "           79,  6017,  1059,   540,  9152,     8,    55,  3230,     4,    83,\n",
      "          919,     9,     5,  1289,  1052,   165,    13,     5,   311,    21,\n",
      "          602,    81,    10,   400,  1218,     8,   553,    69,     7,  1203,\n",
      "           62,     4,   407,   172,    79,    56,    41,  2936,     7,  3594,\n",
      "           69,     8,   860,     7,   120,  4502,    13,    69,     4,     2,\n",
      "            1,     1], device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "Part 1: tensor([    0,  2688,    35,  2341,  1215, 39402,     2], device='cuda:0')\n",
      "Part 2: tensor([    0, 48931,     9, 19584,    35, 12881,     5,   335,     4, 41852,\n",
      "            9, 19584,    35,   733,     4, 33854,    35,   849, 41761,   134,\n",
      "        10431,    35,    38,   437,   259,     7,  2883,     5,  1013, 18023,\n",
      "            9, 13555,  1207,    11,  3332,     4,   152,    16,   127,   544,\n",
      "         4576,  1886,     4, 50118, 10431, 41761,   176, 10431,    35,  4954,\n",
      "            4,   653,   109,    47,   236,     7,   216,   116, 50118, 10431,\n",
      "        41761,   134, 10431,    35,   166,   129,   240,     7, 12881,   110,\n",
      "          335,   136,    84,  2189,     4, 50118, 10431, 41761,   176, 10431,\n",
      "           35,  4954,     4, 50118, 10431, 41761,   134, 10431,    35,  3401,\n",
      "          311,   162,   110, 12373,     8,  4787, 17444,  2595,  8974,     4,\n",
      "        50118, 10431, 41761,   176, 10431,    35,  1398,    47,    32,     4,\n",
      "        50118, 10431, 41761,   134, 10431,    35,  1336,   251,    33,    47,\n",
      "           57,  1207,   259,   116, 50118, 10431, 41761,   176, 10431,    35,\n",
      "         1596,   107,     4, 50118, 10431, 41761,   134, 10431,    35,   392,\n",
      "           38,   216,   110, 14349,   116, 50118, 10431, 41761,   176, 10431,\n",
      "           35,    38,   437,    10,  3097,    23,    10,  2737,     4, 50118,\n",
      "        10431, 41761,   134, 10431,    35,  1534,    14,   235,   116,  6834,\n",
      "         2737,     6,   114,    47,   218,    75,  1508,   127,  1996,   116,\n",
      "        50118, 10431, 41761,   176, 10431,    35,    38,  6396,    23,  3332,\n",
      "        26411,   589,     6,  2370, 15229,     8,   103, 28726,  5033,  4050,\n",
      "            4, 50118, 10431, 41761,   134, 10431,    35,  9567,  2092,     7,\n",
      "           28,    11,   645,     4,  3837,    47,    13,   110,    86,     4,\n",
      "            2,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# = = = = = = = = = = = = = = = = Train = = = = = = = = = = = = = = = = = = =\n",
    "total_batch_size = args.per_device_train_batch_size * \\\n",
    "    accelerator.num_processes * args.gradient_accumulation_steps\n",
    "\n",
    "logger.info(\"***** Running training *****\")\n",
    "logger.info(f\" Num examples = {len(train_dataset)}\")\n",
    "logger.info(f\" Num Epochs = {args.num_train_epochs}\")\n",
    "logger.info(\n",
    "    f\" Instantaneous batch size per device = {args.per_device_train_batch_size}\")\n",
    "logger.info(\n",
    "    f\" Total train batch size (w. parallel, distributed & accumulation) = {total_batch_size}\")\n",
    "logger.info(\n",
    "    f\" Gradient Accumulation steps = {args.gradient_accumulation_steps}\")\n",
    "logger.info(f\" Total optimization steps = {args.max_train_steps}\")\n",
    "\n",
    "# Only show the progress bar once on each machine.\n",
    "progress_bar = tqdm(range(args.max_train_steps), desc=\"Training: \",\n",
    "                    disable=not accelerator.is_local_main_process)\n",
    "completed_steps = 0\n",
    "\n",
    "val_results = []\n",
    "acc_losses = []\n",
    "best_r2_f1 = None\n",
    "best_epoch = 0\n",
    "\n",
    "# edit #\n",
    "if args.model_type == 'bart' or args.model_type == 't5':\n",
    "    # task_specific_params = model.module.config.task_specific_params\n",
    "    task_specific_params = model.config.task_specific_params\n",
    "    params = task_specific_params.get('summarization', {})\n",
    "    params['min_length'] = args.min_target_length\n",
    "    params['max_length'] = args.max_target_length\n",
    "    params['length_penalty'] = args.length_penalty\n",
    "    params['num_beams'] = args.num_beams\n",
    "    # model.module.config.update(params)\n",
    "    model.config.update(params)\n",
    "else:\n",
    "    raise ValueError(\n",
    "        '{} model type not implemented'.format(args.model_type))\n",
    "\n",
    "loss_list = []\n",
    "train_loss_list = []\n",
    "val_loss_list = []\n",
    "last_output = None\n",
    "hidden_states = None\n",
    "\n",
    "# =  =  =  =  =  =  =  =  =  =  =  =  =  =  =  = Train =  =  =  =  =  =  =  =  =  =  =  =  =  =  =\n",
    "for epoch in range(args.num_train_epochs):\n",
    "    # train\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        if args.ctrlen_model:  # CTRLen model\n",
    "            outputs, loss = model(batch, tokenizer)\n",
    "        # w/ and w/o label smoothing (always better with label smoothing)\n",
    "        else:\n",
    "            if args.label_smoothing == 0:\n",
    "                outputs = model(**batch)\n",
    "                loss = outputs.loss\n",
    "            else:\n",
    "                # outputs = model(**batch, output_hidden_states=True)\n",
    "                input_ids = batch[\"input_ids\"]\n",
    "                for original_tensor in input_ids:\n",
    "                    # print\n",
    "                    # print(i)\n",
    "                    split_value = 2\n",
    "                    split_index = (original_tensor == split_value).nonzero(as_tuple=True)[0][0]\n",
    "                    print(split_index)\n",
    "                    part1 = original_tensor[:split_index + 1]\n",
    "                    part2 = original_tensor[split_index + 1:]\n",
    "                    print(\"Part 1:\", part1)\n",
    "                    print(\"Part 2:\", part2)\n",
    "                    split_value_2 = 2\n",
    "                    split_index_2 = (part2 == split_value_2).nonzero(as_tuple=True)[0][0]\n",
    "                    print(split_index_2)\n",
    "                    part3 = part2[:split_index_2 + 1]\n",
    "                    part4 = part2[split_index_2 + 1:]\n",
    "                break\n",
    "                attention_mask = batch[\"attention_mask\"]\n",
    "                target_ids = batch[\"decoder_input_ids\"]\n",
    "                outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=target_ids, output_hidden_states=True)\n",
    "                last_output = outputs\n",
    "                output_logits = outputs.logits\n",
    "                hidden_states = outputs.decoder_hidden_states\n",
    "                # print(f\"logits: {output_logits.shape}\")\n",
    "                # print(\"=\"*100)\n",
    "                # # print(f\"hidden states: {hidden_states.shape}\")\n",
    "                # print(f\"loss: {outputs.loss}\")\n",
    "                # print(outputs.keys())\n",
    "                # print(\"=\"*100)\n",
    "                output_probs = torch.nn.functional.log_softmax(\n",
    "                    output_logits, dim=-1)\n",
    "                # edit #\n",
    "                # output_probs = output_probs.view(-1,\n",
    "                #                                  model.module.config.vocab_size)\n",
    "                output_probs = output_probs.view(-1,\n",
    "                                                 model.config.vocab_size)\n",
    "\n",
    "                gt_logits = batch['labels']\n",
    "                # print(f\"label: {gt_logits.shape}\")\n",
    "                # print(\"=\"*100)\n",
    "                gt_logits = gt_logits.view(-1)\n",
    "\n",
    "                # print(f\"output_probs: {output_probs.shape}\")\n",
    "                # print(\"-\"*100)\n",
    "                # print(f\"gt_logits: {gt_logits.shape}\")\n",
    "                # print(\"=\"*100)\n",
    "\n",
    "                loss_nll, nll = label_smoothed_nll_loss(\n",
    "                    output_probs, gt_logits, args.label_smoothing, ignore_index=tokenizer.pad_token_id)\n",
    "\n",
    "                cosine_loss = torch.nn.CosineEmbeddingLoss()\n",
    "\n",
    "                loss_cs = cosine_loss(outputs.encoder_last_hidden_state[0], outputs.encoder_last_hidden_state[1], torch.ones(outputs.encoder_last_hidden_state.size(dim=1)).to(torch.device('cuda')))\n",
    "\n",
    "                alpha = 0.5\n",
    "\n",
    "                loss = loss_nll + alpha * (1 - loss_cs)\n",
    "\n",
    "                # print(f\"loss_fn: {loss}\")\n",
    "                # print(\"-\"*100)\n",
    "                # print(f\"nll: {nll}\")\n",
    "                # print(\"=\"*100)\n",
    "                # break\n",
    "        break\n",
    "        acc_losses.append(loss.item())\n",
    "        loss_list.append(loss)\n",
    "        epoch_loss += loss.item()\n",
    "        loss = loss / args.gradient_accumulation_steps\n",
    "        # print(f\"loss_grad: {loss}\")\n",
    "        accelerator.backward(loss)\n",
    "        # break\n",
    "\n",
    "        if step % args.gradient_accumulation_steps == 0 or step == len(train_dataloader) - 1:\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "            progress_bar.update(1)\n",
    "            progress_bar.set_postfix(lr=lr_scheduler.get_last_lr()[\n",
    "                                     0], loss=np.mean(acc_losses[-50:]))\n",
    "            completed_steps += 1\n",
    "            train_loss_list.append(epoch_loss/len(batch))\n",
    "\n",
    "        if completed_steps >= args.max_train_steps:\n",
    "            break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>ID: train_6222</s><s>Topic of Summary: go out. Length of Summary: 32. Dialogue:']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(torch.tensor([[0,  2688,    35,  2341,  1215,   401, 16986,     2,     0, 48931,\n",
    "            9, 19584,    35,   213,    66,     4, 41852,     9, 19584,    35,\n",
    "         2107,     4, 33854,    35,]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "c93c25e40e054458b7dfbd865069cadd"
     ]
    },
    "id": "awYeoAgOsu3Z",
    "outputId": "332daa87-c3c6-4fef-edcb-0e5124a48f23",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10/14/2023 12:48:59 - INFO - __main__ - ***** Running training *****\n",
      "10/14/2023 12:48:59 - INFO - __main__ -  Num examples = 12460\n",
      "10/14/2023 12:48:59 - INFO - __main__ -  Num Epochs = 5\n",
      "10/14/2023 12:48:59 - INFO - __main__ -  Instantaneous batch size per device = 2\n",
      "10/14/2023 12:48:59 - INFO - __main__ -  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "10/14/2023 12:48:59 - INFO - __main__ -  Gradient Accumulation steps = 64\n",
      "10/14/2023 12:48:59 - INFO - __main__ -  Total optimization steps = 490\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f889b4e418824e8c8ad7d54bd99ce8dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/490 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"max_length\": 128,\n",
      "  \"min_length\": 1,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1\n",
      "}\n",
      "\n",
      "/home/worachotn/.local/lib/python3.10/site-packages/transformers/generation/utils.py:1421: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([    0,  4576,    35,  2341,  1215,   401, 16986,     4,  1437,     2,\n",
      "        48931,     9, 19584,    35,   213,    66,     4, 41852,     9, 19584,\n",
      "           35,  2107,     4, 33854,    35,   849, 41761,   134, 10431,    35,\n",
      "        12289,     6,  2206,     6,   141,    32,   383,   116, 50118, 10431,\n",
      "        41761,   176, 10431,    35, 12289,     6, 18320,     4,  2497,     6,\n",
      "         2446,     4,   653,    18,    92,    19,    47,   116, 50118, 10431,\n",
      "        41761,   134, 10431,    35,  5534,     6,    38,    21,    95,  8020,\n",
      "          114,    47,   236,     7,   213,    66,  3422,     4, 50118, 10431,\n",
      "        41761,   176, 10431,    35,  2647,     6,    38,    21,  2053,     9,\n",
      "          164,     7,     5,  2737,  5560,     7,   109,    10,   828,     9,\n",
      "          892,     4,   653,   348,    47,   300,    15,  1508,   116, 50118,\n",
      "        10431, 41761,   134, 10431,    35,    38,   802,    52,    95,   213,\n",
      "           13,    10,  1656,   116,  5359,   159,     5,  2221,   583,     5,\n",
      "         4105,     4, 50118, 10431, 41761,   176, 10431,    35, 11765,   116,\n",
      "          370,   531,    28, 22024,   328,    85,    18,   350,  2569,     4,\n",
      "        50118, 10431, 41761,   134, 10431,    35,  5534,     6,  4420,     4,\n",
      "           85,    18,   350,  2569,     4,   125,    38,   202,   236,     7,\n",
      "          213,    66,  6152,     4,   280,   188,  3171, 40192, 32411,    16,\n",
      "           15,    11,     5,  1139,     4,  1336,    59,    14,   116, 50118,\n",
      "        10431, 41761,   176, 10431,    35,  4954,     4,   653,    86,   473,\n",
      "           24,   386,   116, 50118, 10431, 41761,   134, 10431,    35,  5534,\n",
      "            6,    38,   206,    24,    18,   457,   375,   799,     6,   402,\n",
      "            4,    38,   581,   120,    10,  2225,     8,    33,    10,   356,\n",
      "            4,  1801,  1004,    15,    13,    10,  2289,     4,  6893,     6,\n",
      "            5,   822,    36, 11990,    43,   300,    10,  5500,  1551,    94,\n",
      "          186,     4, 50118, 10431, 41761,   176, 10431,    35,  4954,     4,\n",
      "         4954,     4,  4820,    32,    52,   164,     7,   972,   116, 50118,\n",
      "        10431, 41761,   134, 10431,    35,    85,  1017,    28,  3013,   114,\n",
      "           52,   972,    23,     5, 11605,     4, 50118, 10431, 41761,   176,\n",
      "        10431,    35,  4954,     4,  4820,    16,    24,   116, 50118, 10431,\n",
      "        41761,   134, 10431,    35,  5534,     6,    47,   216,     6,     5,\n",
      "        17311,  4911,  1097,     4, 50118, 10431, 41761,   176, 10431,    35,\n",
      "         4820,    16,    14,   116, 50118, 10431, 41761,   134, 10431,    35,\n",
      "        15729,     5,  1139,  5179,    23,     5,  5483,     9,     5,   788,\n",
      "            4, 50118, 10431, 41761,   176, 10431,    35,  5534,     6,  4420,\n",
      "            4,    38,   216,   147,    24,    16,     4,  4954,     4,  6893,\n",
      "            6,    38,   581,   972,    47,    89,    23, 23843,   375,   799,\n",
      "            4,     2,     1,     1,     1,     1], device='cuda:0')\n",
      "tensor([    0,  4576,    35,  2341,  1215,   401, 35324,     4,  1437,     2,\n",
      "        48931,     9, 19584,    35,    28,  7464,     4, 41852,     9, 19584,\n",
      "           35,   601,     4, 33854,    35,   849, 41761,   134, 10431,    35,\n",
      "           38,  4443,    38,   437,    95,    10,   410,  7464,     4,    38,\n",
      "          437,  1311,   960,    38,    33,     7, 36312,     6,     8,   734,\n",
      "        50118, 10431, 41761,   176, 10431,    35,     8,    99,   114,    24,\n",
      "          630,    75,   173,    66,     6,   235,   116, 50118, 10431, 41761,\n",
      "          134, 10431,    35, 31804,     4, 50118, 10431, 41761,   176, 10431,\n",
      "           35,   370,   240,     7,  6602,  2053,   101,    10, 22650,     4,\n",
      "        36312,    16,   164,     7,  3151, 17507,     4,   370,   216,   141,\n",
      "           38,   216,   116, 50118, 10431, 41761,   134, 10431,    35,  1336,\n",
      "          116, 50118, 10431, 41761,   176, 10431,    35,  3047,    38,   351,\n",
      "           75,   905,    24,  5998,     4, 50118, 10431, 41761,   134, 10431,\n",
      "           35,   125,    99,    59,  3859,   116,   653,   114,  7144,     4,\n",
      "         3137, 11703,     7,   213,    19,  6494, 43438,     6,     8,    45,\n",
      "          201,   116,     2,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"max_length\": 128,\n",
      "  \"min_length\": 1,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"max_length\": 128,\n",
      "  \"min_length\": 1,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"max_length\": 128,\n",
      "  \"min_length\": 1,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"max_length\": 128,\n",
      "  \"min_length\": 1,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"max_length\": 128,\n",
      "  \"min_length\": 1,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"max_length\": 128,\n",
      "  \"min_length\": 1,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"max_length\": 128,\n",
      "  \"min_length\": 1,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"max_length\": 128,\n",
      "  \"min_length\": 1,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"max_length\": 128,\n",
      "  \"min_length\": 1,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"max_length\": 128,\n",
      "  \"min_length\": 1,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"max_length\": 128,\n",
      "  \"min_length\": 1,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"max_length\": 128,\n",
      "  \"min_length\": 1,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"max_length\": 128,\n",
      "  \"min_length\": 1,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"max_length\": 128,\n",
      "  \"min_length\": 1,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"max_length\": 128,\n",
      "  \"min_length\": 1,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"max_length\": 128,\n",
      "  \"min_length\": 1,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"max_length\": 128,\n",
      "  \"min_length\": 1,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"max_length\": 128,\n",
      "  \"min_length\": 1,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"max_length\": 128,\n",
      "  \"min_length\": 1,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"max_length\": 128,\n",
      "  \"min_length\": 1,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"max_length\": 128,\n",
      "  \"min_length\": 1,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"max_length\": 128,\n",
      "  \"min_length\": 1,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"max_length\": 128,\n",
      "  \"min_length\": 1,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"max_length\": 128,\n",
      "  \"min_length\": 1,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"max_length\": 128,\n",
      "  \"min_length\": 1,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"max_length\": 128,\n",
      "  \"min_length\": 1,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"max_length\": 128,\n",
      "  \"min_length\": 1,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"max_length\": 128,\n",
      "  \"min_length\": 1,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"max_length\": 128,\n",
      "  \"min_length\": 1,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# = = = = = = = = = = = = = = = = Train = = = = = = = = = = = = = = = = = = =\n",
    "total_batch_size = args.per_device_train_batch_size * \\\n",
    "    accelerator.num_processes * args.gradient_accumulation_steps\n",
    "\n",
    "logger.info(\"***** Running training *****\")\n",
    "logger.info(f\" Num examples = {len(train_dataset)}\")\n",
    "logger.info(f\" Num Epochs = {args.num_train_epochs}\")\n",
    "logger.info(\n",
    "    f\" Instantaneous batch size per device = {args.per_device_train_batch_size}\")\n",
    "logger.info(\n",
    "    f\" Total train batch size (w. parallel, distributed & accumulation) = {total_batch_size}\")\n",
    "logger.info(\n",
    "    f\" Gradient Accumulation steps = {args.gradient_accumulation_steps}\")\n",
    "logger.info(f\" Total optimization steps = {args.max_train_steps}\")\n",
    "\n",
    "# Only show the progress bar once on each machine.\n",
    "progress_bar = tqdm(range(args.max_train_steps), desc=\"Training: \",\n",
    "                    disable=not accelerator.is_local_main_process)\n",
    "completed_steps = 0\n",
    "\n",
    "val_results = []\n",
    "acc_losses = []\n",
    "best_r2_f1 = None\n",
    "best_epoch = 0\n",
    "\n",
    "# edit #\n",
    "if args.model_type == 'bart' or args.model_type == 't5':\n",
    "    # task_specific_params = model.module.config.task_specific_params\n",
    "    task_specific_params = model.config.task_specific_params\n",
    "    params = task_specific_params.get('summarization', {})\n",
    "    params['min_length'] = args.min_target_length\n",
    "    params['max_length'] = args.max_target_length\n",
    "    params['length_penalty'] = args.length_penalty\n",
    "    params['num_beams'] = args.num_beams\n",
    "    # model.module.config.update(params)\n",
    "    model.config.update(params)\n",
    "else:\n",
    "    raise ValueError(\n",
    "        '{} model type not implemented'.format(args.model_type))\n",
    "\n",
    "loss_list = []\n",
    "train_loss_list = []\n",
    "val_loss_list = []\n",
    "last_output = None\n",
    "hidden_states = None\n",
    "\n",
    "# =  =  =  =  =  =  =  =  =  =  =  =  =  =  =  = Train =  =  =  =  =  =  =  =  =  =  =  =  =  =  =\n",
    "for epoch in range(args.num_train_epochs):\n",
    "    # train\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        if args.ctrlen_model:  # CTRLen model\n",
    "            outputs, loss = model(batch, tokenizer)\n",
    "        # w/ and w/o label smoothing (always better with label smoothing)\n",
    "        else:\n",
    "            if args.label_smoothing == 0:\n",
    "                outputs = model(**batch)\n",
    "                loss = outputs.loss\n",
    "            else:\n",
    "                # outputs = model(**batch, output_hidden_states=True)\n",
    "                input_ids = batch[\"input_ids\"]\n",
    "                for i in input_ids:\n",
    "                    print(i)\n",
    "                break\n",
    "                attention_mask = batch[\"attention_mask\"]\n",
    "                target_ids = batch[\"decoder_input_ids\"]\n",
    "                outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=target_ids, output_hidden_states=True)\n",
    "                last_output = outputs\n",
    "                output_logits = outputs.logits\n",
    "                hidden_states = outputs.decoder_hidden_states\n",
    "                # print(f\"logits: {output_logits.shape}\")\n",
    "                # print(\"=\"*100)\n",
    "                # # print(f\"hidden states: {hidden_states.shape}\")\n",
    "                # print(f\"loss: {outputs.loss}\")\n",
    "                # print(outputs.keys())\n",
    "                # print(\"=\"*100)\n",
    "                output_probs = torch.nn.functional.log_softmax(\n",
    "                    output_logits, dim=-1)\n",
    "                # edit #\n",
    "                # output_probs = output_probs.view(-1,\n",
    "                #                                  model.module.config.vocab_size)\n",
    "                output_probs = output_probs.view(-1,\n",
    "                                                 model.config.vocab_size)\n",
    "\n",
    "                gt_logits = batch['labels']\n",
    "                # print(f\"label: {gt_logits.shape}\")\n",
    "                # print(\"=\"*100)\n",
    "                gt_logits = gt_logits.view(-1)\n",
    "\n",
    "                # print(f\"output_probs: {output_probs.shape}\")\n",
    "                # print(\"-\"*100)\n",
    "                # print(f\"gt_logits: {gt_logits.shape}\")\n",
    "                # print(\"=\"*100)\n",
    "\n",
    "                loss_nll, nll = label_smoothed_nll_loss(\n",
    "                    output_probs, gt_logits, args.label_smoothing, ignore_index=tokenizer.pad_token_id)\n",
    "\n",
    "                cosine_loss = torch.nn.CosineEmbeddingLoss()\n",
    "\n",
    "                loss_cs = cosine_loss(outputs.encoder_last_hidden_state[0], outputs.encoder_last_hidden_state[1], torch.ones(outputs.encoder_last_hidden_state.size(dim=1)).to(torch.device('cuda')))\n",
    "\n",
    "                alpha = 0.5\n",
    "\n",
    "                loss = loss_nll + alpha * (1 - loss_cs)\n",
    "\n",
    "                # print(f\"loss_fn: {loss}\")\n",
    "                # print(\"-\"*100)\n",
    "                # print(f\"nll: {nll}\")\n",
    "                # print(\"=\"*100)\n",
    "                # break\n",
    "\n",
    "        acc_losses.append(loss.item())\n",
    "        loss_list.append(loss)\n",
    "        epoch_loss += loss.item()\n",
    "        loss = loss / args.gradient_accumulation_steps\n",
    "        # print(f\"loss_grad: {loss}\")\n",
    "        accelerator.backward(loss)\n",
    "        # break\n",
    "\n",
    "        if step % args.gradient_accumulation_steps == 0 or step == len(train_dataloader) - 1:\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "            progress_bar.update(1)\n",
    "            progress_bar.set_postfix(lr=lr_scheduler.get_last_lr()[\n",
    "                                     0], loss=np.mean(acc_losses[-50:]))\n",
    "            completed_steps += 1\n",
    "            train_loss_list.append(epoch_loss/len(batch))\n",
    "\n",
    "        if completed_steps >= args.max_train_steps:\n",
    "            break\n",
    "\n",
    "    # # =  =  =  =  =  =  =  =  =  =  =  =  =  =  =  = EVAL =  =  =  =  =  =  =  =  =  =  =  =  =  =  =\n",
    "    model.eval()\n",
    "    val_predict = []\n",
    "    val_groundtruth = []\n",
    "    for step, batch in enumerate(eval_dataloader):\n",
    "        with torch.no_grad():\n",
    "            val_loss = []\n",
    "            generated_tokens = accelerator.unwrap_model(model).generate(\n",
    "                batch[\"input_ids\"],\n",
    "                attention_mask=batch[\"attention_mask\"]\n",
    "            )\n",
    "\n",
    "            # print(generated_tokens)\n",
    "            # print(\"=\"*100)\n",
    "\n",
    "            generated_tokens = accelerator.pad_across_processes(\n",
    "                generated_tokens, dim=1, pad_index=tokenizer.pad_token_id\n",
    "            )\n",
    "\n",
    "            # print(generated_tokens)\n",
    "            # print(\"=\"*100)\n",
    "\n",
    "            labels = batch[\"labels\"]\n",
    "            if not args.pad_to_max_length:\n",
    "                # If we did not pad to max length, we need to pad the labels too\n",
    "                labels = accelerator.pad_across_processes(\n",
    "                    batch[\"labels\"], dim=1, pad_index=tokenizer.pad_token_id)\n",
    "\n",
    "            # print(generated_tokens)\n",
    "            # print(\"=\"*100)\n",
    "            # print(labels)\n",
    "            # print(\"=\"*100)\n",
    "            # loss, _ = label_smoothed_nll_loss_gen(generated_tokens, labels, args.label_smoothing, ignore_index=tokenizer.pad_token_id)\n",
    "            # break\n",
    "            # loss, _ = map(label_smoothed_nll_loss, generated_tokens, labels, args.label_smoothing, ignore_index=tokenizer.pad_token_id)\n",
    "            # val_loss.extend(loss)\n",
    "\n",
    "            generated_tokens = accelerator.gather(generated_tokens).cpu().numpy()\n",
    "            labels = accelerator.gather(labels).cpu().numpy()\n",
    "\n",
    "            if args.ignore_pad_token_for_loss:\n",
    "                # Replace -100 in the labels as we can't decode them.\n",
    "                labels = np.where(labels != -100, labels,\n",
    "                                tokenizer.pad_token_id)\n",
    "            if isinstance(generated_tokens, tuple):\n",
    "                generated_tokens = generated_tokens[0]\n",
    "\n",
    "            # print(generated_tokens[0])\n",
    "            # print(\"=\"*100)\n",
    "            # print(labels[0])\n",
    "            # loss, _ = label_smoothed_nll_loss(generated_tokens[0], labels[0], args.label_smoothing, ignore_index=tokenizer.pad_token_id)\n",
    "            # break\n",
    "\n",
    "            decoded_preds = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n",
    "            decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "            # print(decoded_preds)\n",
    "            # print(\"=\"*100)\n",
    "            # print(decoded_labels)\n",
    "            # print(\"=\"*100)\n",
    "\n",
    "            decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
    "\n",
    "            # print(decoded_preds)\n",
    "            # print(\"=\"*100)\n",
    "            # print(decoded_labels)\n",
    "            # print(\"=\"*100)\n",
    "            # if step == 1:\n",
    "            #     break\n",
    "\n",
    "            val_predict.extend(decoded_preds)\n",
    "            val_groundtruth.extend(decoded_labels)\n",
    "\n",
    "    if args.len_output == 'real':\n",
    "        new_val_predict = []\n",
    "        for sample in val_predict:\n",
    "            try:\n",
    "                gen_sum = sample.split('Summary: ')[2]\n",
    "                new_val_predict.append(gen_sum)\n",
    "            except:\n",
    "                new_val_predict.append(sample)\n",
    "        val_predict = new_val_predict\n",
    "    else:\n",
    "        new_val_predict = val_predict\n",
    "\n",
    "    logger.info(\"\")\n",
    "    logger.info(\"Rouge score on val set after epoch {}\".format(epoch+1))\n",
    "    eval_results = py_rouge_scores(val_predict, val_groundtruth)\n",
    "\n",
    "    if best_r2_f1 is None:\n",
    "        best_r2_f1 = eval_results\n",
    "    if eval_results['rouge-2']['f'] >= best_r2_f1['rouge-2']['f']:\n",
    "        best_r2_f1 = eval_results\n",
    "        best_epoch = epoch + 1\n",
    "\n",
    "        os.makedirs(args.output_dir+'/best', exist_ok=True)\n",
    "        accelerator.wait_for_everyone()\n",
    "        unwrapped_model = accelerator.unwrap_model(model)\n",
    "        unwrapped_model.save_pretrained(\n",
    "            args.output_dir+'/best', save_function=accelerator.save)\n",
    "        if accelerator.is_main_process:\n",
    "            tokenizer.save_pretrained(args.output_dir+'/best')\n",
    "        # save vocab\n",
    "        vocab = tokenizer.vocab.copy()\n",
    "        vocab = {k: v for k, v in sorted(\n",
    "            vocab.items(), key=lambda item: item[1])}\n",
    "        with open(args.output_dir + '/best/vocab.txt', 'w') as f:\n",
    "            for word, index in vocab.items():\n",
    "                # it lead to encoding bug on some machines, so i add this line\n",
    "                word = word.encode('ascii', 'ignore').decode('ascii')\n",
    "                f.write(str(index) + ': ' + word + '\\n')\n",
    "\n",
    "    # = = = = = = = = = = = = = = = = = = = = = = = = =\n",
    "    logger.info(\n",
    "        \"Current Best Validation Result is at epoch {}\".format(best_epoch))\n",
    "    py_rouge_scores(None, None, best_r2_f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DTRdH7I6su3a",
    "outputId": "1bdae418-e213-4f73-a779-72e61fde2b04",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(outputs.encoder_last_hidden_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U0Ckx5K5su3b",
    "outputId": "6a0602b6-9e3d-442e-e3d9-486bb7f379a6",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0199,  0.0383,  0.0413,  ..., -0.0192,  0.0033, -0.0034],\n",
       "         [-0.1682, -0.0113,  0.1301,  ..., -0.0883, -0.0093, -0.1615],\n",
       "         [-0.0111, -0.4472,  0.0442,  ...,  0.0226, -0.0170, -0.2872],\n",
       "         ...,\n",
       "         [-0.0308, -0.2955, -0.3913,  ...,  0.0104, -0.0009, -0.0810],\n",
       "         [-0.0451, -0.4547, -0.5451,  ...,  0.1203, -0.0126,  0.1627],\n",
       "         [-0.0310, -0.0535, -0.3161,  ...,  0.0269, -0.0641,  0.1126]],\n",
       "\n",
       "        [[ 0.0211,  0.0319,  0.0484,  ..., -0.0260, -0.0024, -0.0104],\n",
       "         [-0.2227, -0.0779, -0.0718,  ...,  0.0067, -0.0177, -0.0376],\n",
       "         [-0.1187, -0.5692, -0.0248,  ..., -0.0780,  0.0284, -0.4738],\n",
       "         ...,\n",
       "         [-0.0440,  0.1978, -0.3247,  ..., -0.0017,  0.1312,  0.3230],\n",
       "         [-0.1271, -0.3494, -0.5145,  ...,  0.0051,  0.1007,  0.0965],\n",
       "         [-0.1246, -0.2684, -0.6091,  ...,  0.0990,  0.0489, -0.0175]]],\n",
       "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.encoder_last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fko7L0FCsu3c",
    "outputId": "31ce65fa-1a28-40a1-fcd3-917c401f3a3d",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "296"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.encoder_last_hidden_state.size(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WNyUX1MBsu3c",
    "outputId": "a4828cfc-fcea-454f-859f-93b32feb3ad1",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "torch.Size([48, 50266])\n"
     ]
    }
   ],
   "source": [
    "print(len(outputs.logits))\n",
    "print(outputs.logits[0].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DNn3RQYUsu3c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "cosine_loss = torch.nn.CosineEmbeddingLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j_VytNi5su3c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "loss_cs = cosine_loss(outputs.encoder_last_hidden_state[0], outputs.encoder_last_hidden_state[1], torch.ones(outputs.encoder_last_hidden_state.size(dim=1)).to(torch.device('cuda')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QBFlUpC5su3d",
    "outputId": "7192015b-7569-4fed-8a9c-79d4b2833650",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7458, device='cuda:0', grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_cs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      ""
     ]
    },
    "id": "Mh3MeO5hsu3d",
    "outputId": "9500b993-deb4-49f7-fdae-089ecb787d16",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10/04/2023 19:07:23 - INFO - __main__ - Loading Best Result is at epoch 4 for Testing\n",
      "loading configuration file ./output/1-bart-baseline-loss/best/config.json\n",
      "Model config BartConfig {\n",
      "  \"_name_or_path\": \"facebook/bart-large\",\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.1,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 12,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 16,\n",
      "  \"encoder_ffn_dim\": 4096,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 12,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_length\": 128,\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"min_length\": 1,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": false,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 128,\n",
      "      \"min_length\": 1,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_cnn\": {\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 142,\n",
      "      \"min_length\": 56,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_xsum\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 62,\n",
      "      \"min_length\": 11,\n",
      "      \"num_beams\": 6\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.33.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50266\n",
      "}\n",
      "\n",
      "loading file vocab.json\n",
      "loading file merges.txt\n",
      "loading file tokenizer.json\n",
      "loading file added_tokens.json\n",
      "loading file special_tokens_map.json\n",
      "loading file tokenizer_config.json\n",
      "loading weights file ./output/1-bart-baseline-loss/best/pytorch_model.bin\n",
      "Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"max_length\": 128,\n",
      "  \"min_length\": 1,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.33.3\"\n",
      "}\n",
      "\n",
      "All model checkpoint weights were used when initializing BartForConditionalGeneration.\n",
      "\n",
      "All the weights of BartForConditionalGeneration were initialized from the model checkpoint at ./output/1-bart-baseline-loss/best.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BartForConditionalGeneration for predictions without further training.\n",
      "loading configuration file ./output/1-bart-baseline-loss/best/generation_config.json\n",
      "Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"max_length\": 128,\n",
      "  \"min_length\": 1,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.33.3\"\n",
      "}\n",
      "\n",
      "10/04/2023 19:07:29 - INFO - __main__ - Collecting Testing Result...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"max_length\": 128,\n",
      "  \"min_length\": 1,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.33.3\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"max_length\": 128,\n",
      "  \"min_length\": 1,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.33.3\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"max_length\": 128,\n",
      "  \"min_length\": 1,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.33.3\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"max_length\": 128,\n",
      "  \"min_length\": 1,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.33.3\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"max_length\": 128,\n",
      "  \"min_length\": 1,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.33.3\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"max_length\": 128,\n",
      "  \"min_length\": 1,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.33.3\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"max_length\": 128,\n",
      "  \"min_length\": 1,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.33.3\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"max_length\": 128,\n",
      "  \"min_length\": 1,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.33.3\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"max_length\": 128,\n",
      "  \"min_length\": 1,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.33.3\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"max_length\": 128,\n",
      "  \"min_length\": 1,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.33.3\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"max_length\": 128,\n",
      "  \"min_length\": 1,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.33.3\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"max_length\": 128,\n",
      "  \"min_length\": 1,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.33.3\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"max_length\": 128,\n",
      "  \"min_length\": 1,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.33.3\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"max_length\": 128,\n",
      "  \"min_length\": 1,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.33.3\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"max_length\": 128,\n",
      "  \"min_length\": 1,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.33.3\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"max_length\": 128,\n",
      "  \"min_length\": 1,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.33.3\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"max_length\": 128,\n",
      "  \"min_length\": 1,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.33.3\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"max_length\": 128,\n",
      "  \"min_length\": 1,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.33.3\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"max_length\": 128,\n",
      "  \"min_length\": 1,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.33.3\"\n",
      "}\n",
      "\n",
      "10/04/2023 19:08:05 - INFO - __main__ - \n",
      "10/04/2023 19:08:05 - INFO - __main__ - ROUGE score on test set\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic of Summary: communication method. Length of Summary: 27. Dialogue: # Person1 # : Ms. Dawson , I need you to take a dictation for me . # Person2 # : Yes , sir ... # Person1 # : This should go out as an intra-office memorandum to all employees by this afternoon . Are you ready ? # Person2 # : Yes , sir . Go ahead . # Person1 # : Attention all staff ... Effective immediately , all office [TAG]communications[TAG] are restricted to email correspondence and official memos . The use of Instant Message programs by employees during working hours is strictly prohibited . # Person2 # : Sir , does this apply to intra-office [TAG]communications[TAG] only ? Or will it also restrict external [TAG]communications[TAG] ? # Person1 # : It should apply to all [TAG]communications[TAG] , not only in this office between employees , but also any outside [TAG]communications[TAG] . # Person2 # : But sir , many employees use Instant Messaging to communicate with their clients . # Person1 # : They will just have to change their [TAG]communication[TAG] [TAG]methods[TAG] . I do n't want any - one using Instant Messaging in this office . It wastes too much time ! Now , please continue with the memo . Where were we ? # Person2 # : This applies to internal and external [TAG]communications[TAG] . # Person1 # : Yes . Any employee who persists in using Instant Messaging will first receive a warning and be placed on probation . At second offense , the employee will face termination . Any questions regarding this new policy may be directed to department heads . # Person2 # : Is that all ? # Person1 # : Yes . Please get this memo typed up and distributed to all employees before 4 pm .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10/04/2023 19:08:05 - INFO - root - \n",
      "10/04/2023 19:08:05 - INFO - root - \trouge-1:\tP: 37.12\tR: 47.88\tF1: 40.73\n",
      "10/04/2023 19:08:05 - INFO - root - \trouge-2:\tP: 13.30\tR: 17.25\tF1: 14.64\n",
      "10/04/2023 19:08:05 - INFO - root - \trouge-l:\tP: 35.01\tR: 43.23\tF1: 37.96\n",
      "10/04/2023 19:08:05 - INFO - root - \n",
      "10/04/2023 19:08:05 - INFO - __main__ - \n"
     ]
    }
   ],
   "source": [
    "# =  =  =  =  =  =  =  =  =  =  =  =  =  =  =  = Test =  =  =  =  =  =  =  =  =  =  =  =  =  =  =  =  =  =  =\n",
    "# load best model\n",
    "logger.info(\"Loading Best Result is at epoch {} for Testing\".format(best_epoch))\n",
    "\n",
    "unwrapped_model = accelerator.unwrap_model(model)\n",
    "config          = config.from_pretrained(args.output_dir+'/best')\n",
    "tokenizer       = tokenizer.from_pretrained(args.output_dir+'/best', config=config)\n",
    "unwrapped_model = unwrapped_model.from_pretrained(args.output_dir+'/best', config=config)\n",
    "model           = accelerator.prepare(unwrapped_model)\n",
    "\n",
    "if args.model_type == 'bart' or args.model_type == 't5':\n",
    "    task_specific_params = model.config.task_specific_params\n",
    "    params = task_specific_params.get('summarization', {})\n",
    "    params['min_length'] = args.min_target_length\n",
    "    params['max_length'] = args.max_target_length\n",
    "    params['length_penalty'] = args.length_penalty\n",
    "    params['num_beams'] = args.num_beams\n",
    "    model.config.update(params)\n",
    "else:\n",
    "    raise ValueError('{} model type not implemented'.format(args.model_type))\n",
    "\n",
    "# start Test\n",
    "logger.info(\"Collecting Testing Result...\")\n",
    "model.eval()\n",
    "\n",
    "test_predict     = []\n",
    "test_groundtruth = []\n",
    "for step, batch in enumerate(tqdm(test_dataloader, leave=False)):\n",
    "    with torch.no_grad():\n",
    "        generated_tokens = accelerator.unwrap_model(model).generate(\n",
    "            batch[\"input_ids\"],\n",
    "            attention_mask=batch[\"attention_mask\"],\n",
    "        )\n",
    "\n",
    "        generated_tokens = accelerator.pad_across_processes(\n",
    "            generated_tokens, dim=1, pad_index=tokenizer.pad_token_id\n",
    "        )\n",
    "        labels = batch[\"labels\"]\n",
    "\n",
    "        if not args.pad_to_max_length:\n",
    "            # If we did not pad to max length, we need to pad the labels too\n",
    "            labels = accelerator.pad_across_processes(batch[\"labels\"], dim=1, pad_index=tokenizer.pad_token_id)\n",
    "\n",
    "        generated_tokens = accelerator.gather(generated_tokens).cpu().numpy()\n",
    "        labels = accelerator.gather(labels).cpu().numpy()\n",
    "\n",
    "        if args.ignore_pad_token_for_loss:\n",
    "            # Replace -100 in the labels as we can't decode them.\n",
    "            labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "        if isinstance(generated_tokens, tuple):\n",
    "            generated_tokens = generated_tokens[0]\n",
    "\n",
    "        decoded_preds  = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n",
    "        decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "        decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
    "\n",
    "        decoded_preds  = [' '.join(sent.split('\\n')) for sent in decoded_preds]\n",
    "        decoded_labels = [' '.join(sent.split('\\n')) for sent in decoded_labels]\n",
    "\n",
    "        test_predict.extend(decoded_preds)\n",
    "        test_groundtruth.extend(decoded_labels)\n",
    "\n",
    "print(raw_datasets['test']['dialogue'][0])\n",
    "\n",
    "if args.len_output == 'real':\n",
    "    new_test_predict = []\n",
    "    for sample in test_predict:\n",
    "        try:\n",
    "            gen_sum = sample.split('Summary: ')[2]\n",
    "            new_test_predict.append(gen_sum)\n",
    "        except:\n",
    "            new_test_predict.append(sample)\n",
    "    test_predict = new_test_predict\n",
    "\n",
    "logger.info(\"\")\n",
    "logger.info(\"ROUGE score on test set\")\n",
    "test_scores = py_rouge_scores(test_predict, test_groundtruth)\n",
    "logger.info(\"\")\n",
    "\n",
    "\n",
    "# Save generated summaries\n",
    "if args.len_input == 'predict':\n",
    "    os.makedirs(args.output_dir+'/predict_gen_samples', exist_ok=True)\n",
    "else:\n",
    "    os.makedirs(args.output_dir+'/gen_samples', exist_ok=True)\n",
    "\n",
    "for i in range(len(test_predict)):\n",
    "    test_id        = raw_datasets['test']['id'][i]\n",
    "    test_dialogue  = raw_datasets['test']['dialogue'][i]\n",
    "    test_summary   = raw_datasets['test']['summary'][i]\n",
    "    test_predict_s = test_predict[i]\n",
    "\n",
    "    if args.len_input == 'predict':\n",
    "        with open(args.output_dir+'/predict_gen_samples/'+str(test_id)+'.txt', 'w') as f:\n",
    "            test_dialogue = test_dialogue.encode('ascii', 'ignore').decode('ascii')\n",
    "            f.write(test_dialogue)\n",
    "            f.write('\\n\\n')\n",
    "            f.write('Golden Summary:\\n')\n",
    "            test_summary = test_summary.encode('ascii', 'ignore').decode('ascii')\n",
    "            f.write(test_summary)\n",
    "            f.write('\\n\\n')\n",
    "            f.write('Generate Summary:\\n')\n",
    "            test_predict_s = test_predict_s.encode('ascii', 'ignore').decode('ascii')\n",
    "            f.write(test_predict_s)\n",
    "    else:\n",
    "        with open(args.output_dir+'/gen_samples/'+str(test_id)+'.txt', 'w') as f:\n",
    "            test_dialogue = test_dialogue.encode('ascii', 'ignore').decode('ascii')\n",
    "            f.write(test_dialogue)\n",
    "            f.write('\\n\\n')\n",
    "            f.write('Golden Summary:\\n')\n",
    "            test_summary = test_summary.encode('ascii', 'ignore').decode('ascii')\n",
    "            f.write(test_summary)\n",
    "            f.write('\\n\\n')\n",
    "            f.write('Generate Summary:\\n')\n",
    "            test_predict_s = test_predict_s.encode('ascii', 'ignore').decode('ascii')\n",
    "            f.write(test_predict_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dvNEVEiCsu3e"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nuPFvbUWsu3e"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "13bb8c4b9a154bb99c4d38cd2edb631c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "14052c5abfad4231a0d4c8d0e0395a01": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "24272444846441638d4836fd835562dc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_78f6c1bca77640ca92bd87d5995fced5",
       "IPY_MODEL_81669ba2443a489cb535c508333dc974",
       "IPY_MODEL_47ddb2c2d8fa4c278c9d514ace68341f"
      ],
      "layout": "IPY_MODEL_b842e08bc1ca45ee99a868d1dfa4d0db"
     }
    },
    "31409e259c8b4ee7899035ea4ba3f140": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "326356876bd540778d188c41673e04f5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "35f50d433dc14aa28cf0f5a039f7cb87": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "368a820467ad4f4d8198932125f0d357": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3bad8094e9124ab391d945edf4ccca2f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4616558f0ebd466babad0202bc55824d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "47ddb2c2d8fa4c278c9d514ace68341f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_932e4629e7f340c2a5b64d095c46bf4d",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_a26c7dc74d71494787fd32d560594b38",
      "value": " 500/500 [00:01&lt;00:00, 317.13 examples/s]"
     }
    },
    "542a00a050384f5f8f3f7354eb527336": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5a2947306125452c8c25c12e54dc6656": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "78f6c1bca77640ca92bd87d5995fced5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4616558f0ebd466babad0202bc55824d",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_9a4ed651601f4a29b763eed10afafc16",
      "value": "Running tokenizer on dataset: 100%"
     }
    },
    "7f1272db213a4121ae95b5e41061d964": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e69f5057741b46dba3ebb186ef85c6db",
      "max": 1500,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_14052c5abfad4231a0d4c8d0e0395a01",
      "value": 1500
     }
    },
    "81669ba2443a489cb535c508333dc974": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_368a820467ad4f4d8198932125f0d357",
      "max": 500,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f5ece15e08e44905a09d9a2e988a4be4",
      "value": 500
     }
    },
    "852ba2b2a4fd4bbe80a2ecd9c9f6b5fb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b1a15a93c5e746888806f8dd19cf6889",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_35f50d433dc14aa28cf0f5a039f7cb87",
      "value": "Running tokenizer on dataset: 100%"
     }
    },
    "90b25ecb208546f9938652c360ef7a5e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_852ba2b2a4fd4bbe80a2ecd9c9f6b5fb",
       "IPY_MODEL_7f1272db213a4121ae95b5e41061d964",
       "IPY_MODEL_a3ad3e93702041d89b6f505ec6d37411"
      ],
      "layout": "IPY_MODEL_ffcb842d99954cdcaa8fb78e8e3b2215"
     }
    },
    "932e4629e7f340c2a5b64d095c46bf4d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9a4ed651601f4a29b763eed10afafc16": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9c182b108efa471994186923f10871a8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a26c7dc74d71494787fd32d560594b38": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a3ad3e93702041d89b6f505ec6d37411": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3bad8094e9124ab391d945edf4ccca2f",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_31409e259c8b4ee7899035ea4ba3f140",
      "value": " 1500/1500 [00:03&lt;00:00, 414.56 examples/s]"
     }
    },
    "a91a8c5870234ab3bdd0132addb34a20": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b1a15a93c5e746888806f8dd19cf6889": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b842e08bc1ca45ee99a868d1dfa4d0db": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c34934bec45646a8b2ac76c60dc124d5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d0098c03b82d48c9acdc684fbbf54567": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fa32d34f467944f2aaf4a13fdf7a0cf2",
       "IPY_MODEL_e3bc145889c94fc3974e88e46863db89",
       "IPY_MODEL_ddbc6421b4cf487d92cc53fb0ae6f634"
      ],
      "layout": "IPY_MODEL_13bb8c4b9a154bb99c4d38cd2edb631c"
     }
    },
    "ddbc6421b4cf487d92cc53fb0ae6f634": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9c182b108efa471994186923f10871a8",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_c34934bec45646a8b2ac76c60dc124d5",
      "value": " 12460/12460 [00:20&lt;00:00, 564.66 examples/s]"
     }
    },
    "e3bc145889c94fc3974e88e46863db89": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_542a00a050384f5f8f3f7354eb527336",
      "max": 12460,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a91a8c5870234ab3bdd0132addb34a20",
      "value": 12460
     }
    },
    "e69f5057741b46dba3ebb186ef85c6db": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f5ece15e08e44905a09d9a2e988a4be4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "fa32d34f467944f2aaf4a13fdf7a0cf2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5a2947306125452c8c25c12e54dc6656",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_326356876bd540778d188c41673e04f5",
      "value": "Running tokenizer on dataset: 100%"
     }
    },
    "ffcb842d99954cdcaa8fb78e8e3b2215": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
