{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TfGuU-bBsu3J",
    "outputId": "e19cfe61-e01a-4e25-f7d9-d5f86adeedfd",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/worachotn/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/worachotn/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/worachotn/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/worachotn/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "lDTyTH6ysu3O",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()  # Initiate nltk lemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true,
    "id": "BDHK-dEEsu3P",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/worachotn/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/worachotn/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/worachotn/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/worachotn/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import os\n",
    "import pprint\n",
    "import logging\n",
    "\n",
    "import datasets\n",
    "import nltk\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import transformers\n",
    "from accelerate import Accelerator\n",
    "from filelock import FileLock\n",
    "from transformers import AdamW, get_scheduler, set_seed\n",
    "\n",
    "from transformers.file_utils import is_offline_mode\n",
    "from transformers.utils.versions import require_version\n",
    "\n",
    "from args import parse_args\n",
    "from data_loader import raw_data_loader, data_processor\n",
    "from model_loader import model_loader\n",
    "from rouge_s import py_rouge_scores\n",
    "from utils import label_smoothed_nll_loss, postprocess_text\n",
    "from new_loss import margin_ranking_loss, cosine_embedding_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "dZmO8rfYsu3Q",
    "tags": []
   },
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n",
    "    datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "    level=logging.INFO,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "zI3YKK_psu3Q",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    MODEL_MAPPING,\n",
    "    SchedulerType,\n",
    ")\n",
    "\n",
    "# You should update this to your particular problem to have better documentation of `model_type`\n",
    "MODEL_CONFIG_CLASSES = list(MODEL_MAPPING.keys())\n",
    "MODEL_TYPES = tuple(conf.model_type for conf in MODEL_CONFIG_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AD495S_Dsu3S",
    "outputId": "ac6a6306-5a6b-4f3b-ca58-d8d40e6c20cf",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--alpha'], dest='alpha', nargs=None, const=None, default=0.5, type=<class 'float'>, choices=None, required=False, help='ration of computation loss in encoder_hidden_layer', metavar=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import argparse\n",
    "arg_parser = argparse.ArgumentParser(description=\"BART\")\n",
    "arg_parser.add_argument(\"--len_input\", dest=\"len_input\", type=str, default=None, help=\"set up prefix input\",choices=('no', 'topic', 'length', 'topic-length', 'length-topic', 'simple', 'simple-topic-tagger', 'simple-tagger'))\n",
    "arg_parser.add_argument(\"--len_output\", dest=\"len_output\", default=None, help=\"Use the ctrlen model or not\", choices=('no', 'topic', 'length', 'topic-length', 'length-topic'))\n",
    "arg_parser.add_argument(\"--output_dir\", dest=\"output_dir\", type=str, default=\"./output/1\", help=\"default\")\n",
    "arg_parser.add_argument(\"--train_file\", dest=\"train_file\", type=str, default=None, help=\"A csv or a json file containing the training data.\")\n",
    "arg_parser.add_argument(\"--validation_file\", dest=\"validation_file\", type=str, default=None, help=\"A csv or a json file containing the validation data.\")\n",
    "arg_parser.add_argument(\"--test_file\", dest=\"test_file\", type=str, default=None, help=\"A csv or a json file containing the test data.\")\n",
    "arg_parser.add_argument(\"--ignore_pad_token_for_loss\", dest=\"ignore_pad_token_for_loss\", type=bool, default=True, help=\"Whether to ignore the tokens corresponding to \" \"padded labels in the loss computation or not.\",)\n",
    "arg_parser.add_argument(\"--text_column\", dest=\"text_column\", type=str, default=\"dialogue\", help=\"The name of the column in the datasets containing the full texts (for summarization).\")\n",
    "arg_parser.add_argument(\"--summary_column\", dest=\"summary_column\", type=str, default=\"summary\", help=\"The name of the column in the datasets containing the summaries (for summarization).\")\n",
    "arg_parser.add_argument(\"--model_name_or_path\", dest=\"model_name_or_path\", type=str, default=\"facebook/bart-large\", help=\"Path to pretrained model or model identifier from huggingface.co/models.\")\n",
    "arg_parser.add_argument(\"--model_type\", dest=\"model_type\", type=str, default=\"bart\", help=\"Model type to use if training from scratch.\", choices=MODEL_TYPES)\n",
    "arg_parser.add_argument(\"--max_source_length\", dest=\"max_source_length\", type=int, default=1024, help=\"default\")\n",
    "arg_parser.add_argument(\"--source_prefix\", dest=\"source_prefix\", type=str, default=None, help=\"A prefix to add before every source text \" \"(useful for T5 models).\")\n",
    "arg_parser.add_argument(\"--preprocessing_num_workers\", type=int, default=None, help=\"The number of processes to use for the preprocessing.\")\n",
    "# arg_parser.add_argument(\"--overwrite_cache\", dest=\"overwrite_cache\", type=lambda x:bool(strtobool(x)), default=True, help=\"default\")\n",
    "arg_parser.add_argument(\"--overwrite_cache\", dest=\"overwrite_cache\", type=bool, default=None, help=\"Overwrite the cached training and evaluation sets\")\n",
    "arg_parser.add_argument(\"--min_target_length\", dest=\"min_target_length\", type=int, default=1, help=\"The minimal total sequence length for target text\")\n",
    "arg_parser.add_argument(\"--max_target_length\", dest=\"max_target_length\", type=int, default=128, help=\"The maximum total sequence length for target text after \"\n",
    "        \"tokenization. Sequences longer than this will be truncated, sequences shorter will be padded.\"\n",
    "        \"during ``evaluate`` and ``predict``.\")\n",
    "arg_parser.add_argument(\"--num_beams\", dest=\"num_beams\", type=int, default=4, help=\"Number of beams to use for evaluation. This argument will be \"\n",
    "        \"passed to ``model.generate``, which is used during ``evaluate`` and ``predict``.\")\n",
    "arg_parser.add_argument(\"--learning_rate\", dest=\"learning_rate\", type=float, default=5e-5, help=\"Initial learning rate (after the potential warmup period) to use.\")\n",
    "arg_parser.add_argument(\"--pad_to_max_length\", action=\"store_true\", help=\"If passed, pad all samples to `max_length`. Otherwise, dynamic padding is used.\",)\n",
    "arg_parser.add_argument(\"--weight_decay\", dest=\"weight_decay\", type=float, default=1e-3, help=\"Weight decay to use.\")\n",
    "arg_parser.add_argument(\"--label_smoothing\", dest=\"label_smoothing\", type=float, default=0.1, help=\"hyperparameter for label smoothing.\")\n",
    "arg_parser.add_argument(\"--length_penalty\", dest=\"length_penalty\", type=float, default=1.0, help=\"large - longer sequence, small - shorter sequence\")\n",
    "arg_parser.add_argument(\"--num_train_epochs\", dest=\"num_train_epochs\", type=int, default=15, help=\"Total number of training epochs to perform.\")\n",
    "arg_parser.add_argument(\"--per_device_train_batch_size\", dest=\"per_device_train_batch_size\", type=int, default=8, help=\"Batch size (per device) for the training dataloader.\")\n",
    "arg_parser.add_argument(\"--gradient_accumulation_steps\", dest=\"gradient_accumulation_steps\", type=int, default=64, help=\"Number of updates steps to accumulate before performing a backward/update pass.\")\n",
    "arg_parser.add_argument(\"--per_device_eval_batch_size\", dest=\"per_device_eval_batch_size\", type=int, default=8, help=\"Batch size (per device) for the evaluation dataloader.\")\n",
    "arg_parser.add_argument(\"--per_device_test_batch_size\", dest=\"per_device_test_batch_size\", type=int, default=8, help=\"Batch size (per device) for the evaluation dataloader.\")\n",
    "arg_parser.add_argument(\"--num_warmup_steps\", dest=\"num_warmup_steps\", type=int, default=0, help=\"Number of steps for the warmup in the lr scheduler.\")\n",
    "arg_parser.add_argument(\"--cache_dir\", dest=\"cache_dir\", type=str, default=\"./output/cache\", help=\"default\")\n",
    "arg_parser.add_argument(\"--seed\", dest=\"seed\", type=int, default=12345, help=\"default\")\n",
    "# arg_parser.add_argument(\"-f\", required=False) #important\n",
    "arg_parser.add_argument(\"--config_name\", type=str, default=None, help=\"Pretrained config name or path if not the same as model_name\")\n",
    "arg_parser.add_argument(\"--tokenizer_name\", type=str, default=None, help=\"Pretrained tokenizer name or path if not the same as model_name\")\n",
    "arg_parser.add_argument(\"--use_slow_tokenizer\", dest=\"use_slow_tokenizer\", action=\"store_true\", help=\"If passed, will use a slow tokenizer (not backed by the 🤗 Tokenizers library).\")\n",
    "arg_parser.add_argument(\"--max_train_steps\", type=int, default=None, help=\"Total number of training steps to perform. If provided, overrides num_train_epochs.\")\n",
    "arg_parser.add_argument(\"--lr_scheduler_type\", type=SchedulerType, default=\"linear\", help=\"The scheduler type to use.\", choices=[\"linear\", \"cosine\", \"cosine_with_restarts\", \"polynomial\", \"constant\", \"constant_with_warmup\"])\n",
    "arg_parser.add_argument(\"--ctrlen_model\", action='store_true', default=False, help=\"Use the ctrlen model or not\")\n",
    "arg_parser.add_argument(\"--sim_window_size\", type=int, default=5, help=\"window size for computing loss.\")\n",
    "arg_parser.add_argument(\"--sim_loss\", type=float, default=0, help=\"the loss weight for similarity scores.\")\n",
    "arg_parser.add_argument(\"--special_len_token_init\", type=str, default=None, help=\"ways to initialize special token for length (random, zero, token_embs)\")\n",
    "arg_parser.add_argument(\"--embedding_lr\", type=float, default=5e-5, help=\"Initial learning rate for embedding layers.\")\n",
    "arg_parser.add_argument(\"--len_start\", type=int, default=1, help=\"start length.\")\n",
    "arg_parser.add_argument(\"--len_end\", type=int, default=100, help=\"end length.\")\n",
    "arg_parser.add_argument(\"--data_aug\",action='store_true',default=False,help=\"whether to perform data augmentation or not\")\n",
    "arg_parser.add_argument(\"--pred_len\", action='store_true', default=False, help=\"whether to use the golden length or predicted length\")\n",
    "arg_parser.add_argument(\"--shuffle\", action='store_true', default=False, help=\"whether to shuffle the dataset to balance train/validation/test\")\n",
    "arg_parser.add_argument(\"--debug\", action='store_true', default=False, help=\"Use the debug mode or not\")\n",
    "\n",
    "arg_parser.add_argument(\"--topic_tagger\", dest=\"topic_tagger\", type=bool, default=None, help=\"Use topic tag <TAG> or not\")\n",
    "arg_parser.add_argument(\"--decoder_topic_tagger\", dest=\"decoder_topic_tagger\", type=bool, default=False, help=\"Use decoder topic tag [TAG] or not\")\n",
    "arg_parser.add_argument(\"--contrastive_loss\", dest=\"contrastive_loss\", type=bool, default=False, help=\"Use contrastive loss or not\")\n",
    "arg_parser.add_argument(\"--alpha\", dest=\"alpha\", type=float, default=0.5, help=\"ration of computation loss in encoder_hidden_layer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "sizQFLtFsu3T",
    "tags": []
   },
   "outputs": [],
   "source": [
    "args = arg_parser.parse_args('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "-nJe4mEqsu3U",
    "tags": []
   },
   "outputs": [],
   "source": [
    "args.train_file = \"./data/dialogtest/dialogsum.train.jsonl\"\n",
    "args.validation_file = \"./data/dialogtest/dialogsum.dev.jsonl\"\n",
    "args.test_file = \"./data/dialogtest/dialogsum.test.jsonl\"\n",
    "args.text_column = \"dialogue\"\n",
    "args.summary_column = \"summary\"\n",
    "args.model_name_or_path = \"facebook/bart-large\"\n",
    "args.model_type = \"bart\"\n",
    "args.max_source_length = 1024\n",
    "args.min_target_length = 1\n",
    "args.max_target_length = 128\n",
    "args.num_beams = 4\n",
    "args.learning_rate = 5e-5\n",
    "args.weight_decay = 1e-3\n",
    "args.label_smoothing = 0.1\n",
    "args.length_penalty = 1.0\n",
    "args.num_train_epochs = 2\n",
    "args.per_device_train_batch_size = 2\n",
    "args.gradient_accumulation_steps = 64\n",
    "args.per_device_eval_batch_size = 8\n",
    "args.per_device_test_batch_size = 8\n",
    "args.num_warmup_steps = 0\n",
    "args.cache_dir = \"./output/cache\"\n",
    "args.overwrite_cache = True\n",
    "args.seed = 12345\n",
    "\n",
    "args.len_input = 'topic-length'\n",
    "args.len_output = 'topic'\n",
    "args.output_dir = \"./output/1-bart-baseline-loss\"\n",
    "\n",
    "args.topic_tagger = False\n",
    "args.decoder_topic_tagger = False\n",
    "args.contrastive_loss = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XOgOOeeYsu3U",
    "outputId": "bea7709d-f0e9-44b8-b4e7-f9a50bde9a46",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic-length\n",
      "False\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(args.len_input)\n",
    "print(args.topic_tagger)\n",
    "print(args.decoder_topic_tagger)\n",
    "print(args.contrastive_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "tz2ZuJAMsu3X",
    "tags": []
   },
   "outputs": [],
   "source": [
    "raw_datasets = raw_data_loader(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hXOyCtjYvQUH",
    "outputId": "f15f305c-71b5-4c0f-adc7-074cad71fee8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'dialogue', 'negative_dialogue', 'summary', 'negative_summary', 'topic', 'negative_topic'],\n",
       "        num_rows: 1500\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'dialogue', 'negative_dialogue', 'summary', 'negative_summary', 'topic', 'negative_topic'],\n",
       "        num_rows: 50\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'dialogue', 'negative_dialogue', 'summary', 'negative_summary', 'topic', 'negative_topic'],\n",
       "        num_rows: 150\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Topic of Summary: get a check-up. Length of Summary: 30. Dialogue: #Person1#: Hi, Mr. Smith. I'm Doctor Hawkins. Why are you here today?\\n#Person2#: I found it would be a good idea to get a check-up.\\n#Person1#: Yes, well, you haven't had one for 5 years. You should have one every year.\\n#Person2#: I know. I figure as long as there is nothing wrong, why go see the doctor?\\n#Person1#: Well, the best way to avoid serious illnesses is to find out about them early. So try to come at least once a year for your own good.\\n#Person2#: Ok.\\n#Person1#: Let me see here. Your eyes and ears look fine. Take a deep breath, please. Do you smoke, Mr. Smith?\\n#Person2#: Yes.\\n#Person1#: Smoking is the leading cause of lung cancer and heart disease, you know. You really should quit.\\n#Person2#: I've tried hundreds of times, but I just can't seem to kick the habit.\\n#Person1#: Well, we have classes and some medications that might help. I'll give you more information before you leave.\\n#Person2#: Ok, thanks doctor.\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets['train']['dialogue'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Topic of Summary: Valentine's Day. Length of Summary: 30. Dialogue: #Person1#: Hi, Mr. Smith. I'm Doctor Hawkins. Why are you here today?\\n#Person2#: I found it would be a good idea to get a check-up.\\n#Person1#: Yes, well, you haven't had one for 5 years. You should have one every year.\\n#Person2#: I know. I figure as long as there is nothing wrong, why go see the doctor?\\n#Person1#: Well, the best way to avoid serious illnesses is to find out about them early. So try to come at least once a year for your own good.\\n#Person2#: Ok.\\n#Person1#: Let me see here. Your eyes and ears look fine. Take a deep breath, please. Do you smoke, Mr. Smith?\\n#Person2#: Yes.\\n#Person1#: Smoking is the leading cause of lung cancer and heart disease, you know. You really should quit.\\n#Person2#: I've tried hundreds of times, but I just can't seem to kick the habit.\\n#Person1#: Well, we have classes and some medications that might help. I'll give you more information before you leave.\\n#Person2#: Ok, thanks doctor.\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets['train']['negative_dialogue'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Topic of Summary: get a check-up. Summary: Mr. Smith's getting a check-up, and Doctor Hawkins advises him to have one every year. Hawkins'll give some information about their classes and medications to help Mr. Smith quit smoking.\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets['train']['summary'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8LVH7c2csu3X",
    "outputId": "df3ae011-014b-437e-a6ab-8d285a7c979c",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10/28/2023 15:55:52 - INFO - __main__ - Distributed environment: NO\n",
      "Num processes: 1\n",
      "Process index: 0\n",
      "Local process index: 0\n",
      "Device: cuda\n",
      "\n",
      "Mixed precision type: fp16\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accelerator = Accelerator(mixed_precision=\"fp16\")\n",
    "logger.info(accelerator.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "JrjSjmUssu3Y",
    "tags": []
   },
   "outputs": [],
   "source": [
    "logger.setLevel(logging.INFO if accelerator.is_local_main_process else logging.ERROR)\n",
    "accelerator.is_local_main_process\n",
    "datasets.utils.logging.set_verbosity_warning()\n",
    "transformers.utils.logging.set_verbosity_info()\n",
    "set_seed(args.seed)\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "accelerator.is_main_process\n",
    "os.makedirs(args.output_dir, exist_ok=True)\n",
    "accelerator.wait_for_everyone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9y_Gspbqsu3Y",
    "outputId": "aac050f9-7369-4b98-f0fa-343cfa962896",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at ./output/cache/models--facebook--bart-large/snapshots/cb48c1365bd826bd521f650dc2e0940aee54720c/config.json\n",
      "Model config BartConfig {\n",
      "  \"_name_or_path\": \"facebook/bart-large\",\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.1,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 12,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 16,\n",
      "  \"encoder_ffn_dim\": 4096,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 12,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": false,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 128,\n",
      "      \"min_length\": 12,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_cnn\": {\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 142,\n",
      "      \"min_length\": 56,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_xsum\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 62,\n",
      "      \"min_length\": 11,\n",
      "      \"num_beams\": 6\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.34.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at ./output/cache/models--facebook--bart-large/snapshots/cb48c1365bd826bd521f650dc2e0940aee54720c/config.json\n",
      "Model config BartConfig {\n",
      "  \"_name_or_path\": \"facebook/bart-large\",\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.1,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 12,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 16,\n",
      "  \"encoder_ffn_dim\": 4096,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 12,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": false,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 128,\n",
      "      \"min_length\": 12,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_cnn\": {\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 142,\n",
      "      \"min_length\": 56,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_xsum\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 62,\n",
      "      \"min_length\": 11,\n",
      "      \"num_beams\": 6\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.34.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading file vocab.json from cache at ./output/cache/models--facebook--bart-large/snapshots/cb48c1365bd826bd521f650dc2e0940aee54720c/vocab.json\n",
      "loading file merges.txt from cache at ./output/cache/models--facebook--bart-large/snapshots/cb48c1365bd826bd521f650dc2e0940aee54720c/merges.txt\n",
      "loading file tokenizer.json from cache at ./output/cache/models--facebook--bart-large/snapshots/cb48c1365bd826bd521f650dc2e0940aee54720c/tokenizer.json\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at ./output/cache/models--facebook--bart-large/snapshots/cb48c1365bd826bd521f650dc2e0940aee54720c/tokenizer_config.json\n",
      "loading configuration file config.json from cache at ./output/cache/models--facebook--bart-large/snapshots/cb48c1365bd826bd521f650dc2e0940aee54720c/config.json\n",
      "Model config BartConfig {\n",
      "  \"_name_or_path\": \"facebook/bart-large\",\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.1,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 12,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 16,\n",
      "  \"encoder_ffn_dim\": 4096,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 12,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": false,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 128,\n",
      "      \"min_length\": 12,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_cnn\": {\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 142,\n",
      "      \"min_length\": 56,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_xsum\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 62,\n",
      "      \"min_length\": 11,\n",
      "      \"num_beams\": 6\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.34.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at ./output/cache/models--facebook--bart-large/snapshots/cb48c1365bd826bd521f650dc2e0940aee54720c/pytorch_model.bin\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1\n",
      "}\n",
      "\n",
      "All model checkpoint weights were used when initializing BartForConditionalGeneration.\n",
      "\n",
      "All the weights of BartForConditionalGeneration were initialized from the model checkpoint at facebook/bart-large.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BartForConditionalGeneration for predictions without further training.\n",
      "Generation config file not found, using a generation config created from the model config.\n",
      "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 50265. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n",
      "Configuration saved in ./output/1-bart-baseline-loss/start/config.json\n",
      "Configuration saved in ./output/1-bart-baseline-loss/start/generation_config.json\n",
      "Model weights saved in ./output/1-bart-baseline-loss/start/pytorch_model.bin\n",
      "tokenizer config file saved in ./output/1-bart-baseline-loss/start/tokenizer_config.json\n",
      "Special tokens file saved in ./output/1-bart-baseline-loss/start/special_tokens_map.json\n"
     ]
    }
   ],
   "source": [
    "config, tokenizer, model = model_loader(accelerator, logger, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50265"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bos_token',\n",
       " 'eos_token',\n",
       " 'unk_token',\n",
       " 'sep_token',\n",
       " 'pad_token',\n",
       " 'cls_token',\n",
       " 'mask_token',\n",
       " 'additional_special_tokens']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.SPECIAL_TOKENS_ATTRIBUTES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.additional_special_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 220,
     "referenced_widgets": [
      "d0098c03b82d48c9acdc684fbbf54567",
      "fa32d34f467944f2aaf4a13fdf7a0cf2",
      "e3bc145889c94fc3974e88e46863db89",
      "ddbc6421b4cf487d92cc53fb0ae6f634",
      "13bb8c4b9a154bb99c4d38cd2edb631c",
      "5a2947306125452c8c25c12e54dc6656",
      "326356876bd540778d188c41673e04f5",
      "542a00a050384f5f8f3f7354eb527336",
      "a91a8c5870234ab3bdd0132addb34a20",
      "9c182b108efa471994186923f10871a8",
      "c34934bec45646a8b2ac76c60dc124d5",
      "24272444846441638d4836fd835562dc",
      "78f6c1bca77640ca92bd87d5995fced5",
      "81669ba2443a489cb535c508333dc974",
      "47ddb2c2d8fa4c278c9d514ace68341f",
      "b842e08bc1ca45ee99a868d1dfa4d0db",
      "4616558f0ebd466babad0202bc55824d",
      "9a4ed651601f4a29b763eed10afafc16",
      "368a820467ad4f4d8198932125f0d357",
      "f5ece15e08e44905a09d9a2e988a4be4",
      "932e4629e7f340c2a5b64d095c46bf4d",
      "a26c7dc74d71494787fd32d560594b38",
      "90b25ecb208546f9938652c360ef7a5e",
      "852ba2b2a4fd4bbe80a2ecd9c9f6b5fb",
      "7f1272db213a4121ae95b5e41061d964",
      "a3ad3e93702041d89b6f505ec6d37411",
      "ffcb842d99954cdcaa8fb78e8e3b2215",
      "b1a15a93c5e746888806f8dd19cf6889",
      "35f50d433dc14aa28cf0f5a039f7cb87",
      "e69f5057741b46dba3ebb186ef85c6db",
      "14052c5abfad4231a0d4c8d0e0395a01",
      "3bad8094e9124ab391d945edf4ccca2f",
      "31409e259c8b4ee7899035ea4ba3f140"
     ]
    },
    "id": "BNku9V-ssu3Y",
    "outputId": "ab678f18-5bfa-4b54-fbb4-cac959f8edcb",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "debf55878d0743fb95c2be5b5fe2f3c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/1500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/worachotn/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3848: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6e79e1b960847daa0c76f8a7ee80f2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/50 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5f9f7b9d1634c16a11a263b6063eb02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/150 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/worachotn/.local/lib/python3.10/site-packages/accelerate/accelerator.py:527: FutureWarning: The `use_fp16` property is deprecated and will be removed in version 1.0 of Accelerate use `Accelerator.mixed_precision == 'fp16'` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "dataloader, processed_dataset = data_processor(logger, args, accelerator, raw_datasets, tokenizer, model)\n",
    "train_dataloader, eval_dataloader, test_dataloader = dataloader\n",
    "train_dataset, _, _ = processed_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HD4JVgBRFOlA",
    "outputId": "8915a69c-5801-4da1-9053-00859e286af5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask', 'negative_input_ids', 'labels', 'negative_labels'],\n",
       "    num_rows: 1500\n",
       "})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 460
    },
    "id": "P7kZdADiv0dl",
    "outputId": "c7280b18-3968-4d9a-a408-1246043ea647"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BartTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "</s><s>Topic of Summary: search for books. Summary: #Person2# is struggling to choose the books about Hollywood in the 30s and 40s. #Person1# suggests he narrow the topic down by listing the specific years he wants. #Person1# tells #Person2# he can look up magazine articles.</s><pad><pad><pad><pad><pad>\n",
      "</s><s>Topic of Summary: English idioms. Summary: Ms. Parker introduces English idioms to #Person1#. #Person1# thinks it's interesting.</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "</s><s>Topic of Summary: search for books. Summary: #Person2# is struggling to choose the books about Hollywood in the 30s and 40s. #Person1# suggests he narrow the topic down by listing the specific years he wants. #Person1# tells #Person2# he can look up magazine articles.</s><pad><pad><pad><pad><pad>\n",
      "</s><s>Topic of Summary: English idioms. Summary: Ms. Parker introduces English idioms to #Person1#. #Person1# thinks it's interesting.</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n"
     ]
    }
   ],
   "source": [
    "for step, batch in enumerate(train_dataloader):\n",
    "  # print(tokenizer.decode(batch['input_ids'][0]))\n",
    "    print(tokenizer.decode(batch['decoder_input_ids'][0]))\n",
    "    print(tokenizer.decode(batch['decoder_input_ids'][1]))\n",
    "    print(tokenizer.decode(batch['decoder_input_ids'][2]))\n",
    "    print(tokenizer.decode(batch['decoder_input_ids'][3]))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'attention_mask', 'labels', 'decoder_input_ids'])\n"
     ]
    }
   ],
   "source": [
    "for step, batch in enumerate(test_dataloader):\n",
    "    print(batch.keys())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'attention_mask', 'labels', 'decoder_input_ids'])\n"
     ]
    }
   ],
   "source": [
    "for step, batch in enumerate(eval_dataloader):\n",
    "    print(batch.keys())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n3z17N4Jsu3Y",
    "outputId": "1849c4bf-2915-4771-b728-98c0e23ab664",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/worachotn/.local/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# = = = Training Preparation = = =\n",
    "# Optimizer\n",
    "# Split weights in two groups, one with weight decay and the other not.\n",
    "no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "\n",
    "if args.ctrlen_model:\n",
    "    no_decay_emb_matrix = [\"bias\", \"LayerNorm.weight\", \"shared\"]\n",
    "else:\n",
    "    no_decay_emb_matrix = [\"bias\", \"LayerNorm.weight\"]\n",
    "\n",
    "optimizer_grouped_parameters = [\n",
    "    {\n",
    "        \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay_emb_matrix)],\n",
    "        \"weight_decay\": args.weight_decay,\n",
    "    },\n",
    "    {\n",
    "        \"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "        \"weight_decay\": 0.0,\n",
    "    },\n",
    "]\n",
    "\n",
    "if args.ctrlen_model:\n",
    "    if args.model_type == 'bart':\n",
    "        optimizer_grouped_parameters.extend([{\n",
    "            \"params\": model.seq2seq_model.model.shared.parameters(),\n",
    "            \"lr\": args.embedding_lr}])\n",
    "    elif args.model_type == 't5':\n",
    "        optimizer_grouped_parameters.extend([{\n",
    "            \"params\": model.seq2seq_model.shared.parameters(),\n",
    "            \"lr\": args.embedding_lr}])\n",
    "    else:\n",
    "        raise ValueError('{} model type not implemented'.format(args.model_type))\n",
    "\n",
    "# optimizer\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=args.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "B9dY-SZEsu3Z",
    "tags": []
   },
   "outputs": [],
   "source": [
    "model, optimizer, train_dataloader, eval_dataloader, test_dataloader = accelerator.prepare(\n",
    "    model, optimizer, train_dataloader, eval_dataloader, test_dataloader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "4b15de89357c428997a59f4e22166ad3"
     ]
    },
    "id": "JBQUGWIqsu3Z",
    "outputId": "062bdecd-ceb2-484a-ab79-13750ecfc0b7",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10/28/2023 13:08:59 - INFO - __main__ - ***** Running training *****\n",
      "10/28/2023 13:08:59 - INFO - __main__ -  Num examples = 1500\n",
      "10/28/2023 13:08:59 - INFO - __main__ -  Num Epochs = 2\n",
      "10/28/2023 13:08:59 - INFO - __main__ -  Instantaneous batch size per device = 2\n",
      "10/28/2023 13:08:59 - INFO - __main__ -  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "10/28/2023 13:08:59 - INFO - __main__ -  Gradient Accumulation steps = 64\n",
      "10/28/2023 13:08:59 - INFO - __main__ -  Total optimization steps = 24\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fe6afc563784152ab5f4941d84f36d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Scheduler and math around the number of training steps.\n",
    "num_update_steps_per_epoch = math.ceil(len(train_dataloader) / args.gradient_accumulation_steps)\n",
    "if args.max_train_steps is None:\n",
    "    args.max_train_steps = args.num_train_epochs * num_update_steps_per_epoch\n",
    "else:\n",
    "    args.num_train_epochs = math.ceil(args.max_train_steps / num_update_steps_per_epoch)\n",
    "\n",
    "lr_scheduler = get_scheduler(\n",
    "    name=args.lr_scheduler_type,\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=args.num_warmup_steps,\n",
    "    num_training_steps=args.max_train_steps,\n",
    ")\n",
    "\n",
    "# = = = = = = = = = = = = = = = = Train = = = = = = = = = = = = = = = = = = =\n",
    "total_batch_size = args.per_device_train_batch_size * accelerator.num_processes * args.gradient_accumulation_steps\n",
    "\n",
    "logger.info(\"***** Running training *****\")\n",
    "logger.info(f\" Num examples = {len(train_dataset)}\")\n",
    "logger.info(f\" Num Epochs = {args.num_train_epochs}\")\n",
    "logger.info(f\" Instantaneous batch size per device = {args.per_device_train_batch_size}\")\n",
    "logger.info(f\" Total train batch size (w. parallel, distributed & accumulation) = {total_batch_size}\")\n",
    "logger.info(f\" Gradient Accumulation steps = {args.gradient_accumulation_steps}\")\n",
    "logger.info(f\" Total optimization steps = {args.max_train_steps}\")\n",
    "\n",
    "# Only show the progress bar once on each machine.\n",
    "progress_bar = tqdm(range(args.max_train_steps), desc=\"Training: \", disable=not accelerator.is_local_main_process)\n",
    "completed_steps = 0\n",
    "\n",
    "val_results = []\n",
    "acc_losses  = []\n",
    "best_r2_f1  = None\n",
    "best_epoch  = 0\n",
    "\n",
    "if args.model_type == 'bart' or args.model_type == 't5':\n",
    "    task_specific_params = model.config.task_specific_params\n",
    "    params = task_specific_params.get('summarization', {})\n",
    "    params['min_length'] = args.min_target_length\n",
    "    params['max_length'] = args.max_target_length\n",
    "    params['length_penalty'] = args.length_penalty\n",
    "    params['num_beams'] = args.num_beams\n",
    "    model.config.update(params)\n",
    "else:\n",
    "    raise ValueError('{} model type not implemented'.format(args.model_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256\n"
     ]
    }
   ],
   "source": [
    "for step, batch in enumerate(train_dataloader):\n",
    "    print(batch['input_ids'].shape[1])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "c93c25e40e054458b7dfbd865069cadd"
     ]
    },
    "id": "awYeoAgOsu3Z",
    "outputId": "332daa87-c3c6-4fef-edcb-0e5124a48f23",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10/28/2023 13:08:59 - INFO - __main__ - ***** Running training *****\n",
      "10/28/2023 13:08:59 - INFO - __main__ -  Num examples = 1500\n",
      "10/28/2023 13:08:59 - INFO - __main__ -  Num Epochs = 2\n",
      "10/28/2023 13:08:59 - INFO - __main__ -  Instantaneous batch size per device = 2\n",
      "10/28/2023 13:08:59 - INFO - __main__ -  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "10/28/2023 13:08:59 - INFO - __main__ -  Gradient Accumulation steps = 64\n",
      "10/28/2023 13:08:59 - INFO - __main__ -  Total optimization steps = 24\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58442ffacca54577979c07f4a1f8ae73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[-1, 1024]' is invalid for input of size 67712",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 91\u001b[0m\n\u001b[1;32m     89\u001b[0m positive_embeddings \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mencoder_last_hidden_state[:divide_num,:,:batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]]\n\u001b[1;32m     90\u001b[0m negative_embeddings \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mencoder_last_hidden_state[divide_num:,:,:batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]]\n\u001b[0;32m---> 91\u001b[0m positive_embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mpositive_embeddings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_position_embeddings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m negative_embeddings \u001b[38;5;241m=\u001b[39m negative_embeddings\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, model\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mmax_position_embeddings)\n\u001b[1;32m     93\u001b[0m contrastive \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mones(positive_embeddings\u001b[38;5;241m.\u001b[39msize(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m))\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[-1, 1024]' is invalid for input of size 67712"
     ]
    }
   ],
   "source": [
    "# = = = = = = = = = = = = = = = = Train = = = = = = = = = = = = = = = = = = =\n",
    "total_batch_size = args.per_device_train_batch_size * \\\n",
    "    accelerator.num_processes * args.gradient_accumulation_steps\n",
    "\n",
    "logger.info(\"***** Running training *****\")\n",
    "logger.info(f\" Num examples = {len(train_dataset)}\")\n",
    "logger.info(f\" Num Epochs = {args.num_train_epochs}\")\n",
    "logger.info(\n",
    "    f\" Instantaneous batch size per device = {args.per_device_train_batch_size}\")\n",
    "logger.info(\n",
    "    f\" Total train batch size (w. parallel, distributed & accumulation) = {total_batch_size}\")\n",
    "logger.info(\n",
    "    f\" Gradient Accumulation steps = {args.gradient_accumulation_steps}\")\n",
    "logger.info(f\" Total optimization steps = {args.max_train_steps}\")\n",
    "\n",
    "# Only show the progress bar once on each machine.\n",
    "progress_bar = tqdm(range(args.max_train_steps), desc=\"Training: \",\n",
    "                    disable=not accelerator.is_local_main_process)\n",
    "completed_steps = 0\n",
    "\n",
    "val_results = []\n",
    "acc_losses = []\n",
    "best_r2_f1 = None\n",
    "best_epoch = 0\n",
    "\n",
    "# edit #\n",
    "if args.model_type == 'bart' or args.model_type == 't5':\n",
    "    # task_specific_params = model.module.config.task_specific_params\n",
    "    task_specific_params = model.config.task_specific_params\n",
    "    params = task_specific_params.get('summarization', {})\n",
    "    params['min_length'] = args.min_target_length\n",
    "    params['max_length'] = args.max_target_length\n",
    "    params['length_penalty'] = args.length_penalty\n",
    "    params['num_beams'] = args.num_beams\n",
    "    # model.module.config.update(params)\n",
    "    model.config.update(params)\n",
    "else:\n",
    "    raise ValueError(\n",
    "        '{} model type not implemented'.format(args.model_type))\n",
    "\n",
    "loss_list = []\n",
    "train_loss_list = []\n",
    "val_loss_list = []\n",
    "last_output = None\n",
    "hidden_states = None\n",
    "\n",
    "# =  =  =  =  =  =  =  =  =  =  =  =  =  =  =  = Train =  =  =  =  =  =  =  =  =  =  =  =  =  =  =\n",
    "for epoch in range(args.num_train_epochs):\n",
    "    # train\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        if args.ctrlen_model:  # CTRLen model\n",
    "            outputs, loss = model(batch, tokenizer)\n",
    "        # w/ and w/o label smoothing (always better with label smoothing)\n",
    "        else:\n",
    "            if args.label_smoothing == 0:\n",
    "                outputs = model(**batch)\n",
    "                loss = outputs.loss\n",
    "            else:\n",
    "                outputs = model(**batch, output_hidden_states=True)\n",
    "                output_logits = outputs.logits\n",
    "\n",
    "                output_probs = torch.nn.functional.log_softmax(\n",
    "                    output_logits, dim=-1)\n",
    "                \n",
    "                if args.contrastive_loss:\n",
    "\n",
    "                    max_encoder_token = batch['input_ids'].shape[1]\n",
    "                    # max_encoder_token = model.config.max_position_embeddings\n",
    "\n",
    "                    divide_num = int(output_probs.shape[0] / 2)\n",
    "                    \n",
    "                    # positive_embeddings_1 = outputs.encoder_last_hidden_state[0]\n",
    "                    # positive_embeddings_2 = outputs.encoder_last_hidden_state[1]\n",
    "                    # negative_embeddings_1 = outputs.encoder_last_hidden_state[2]\n",
    "                    # negative_embeddings_2 = outputs.encoder_last_hidden_state[3]\n",
    "\n",
    "                    # positive_decoder_embeddings_1 = outputs.decoder_hidden_states[-1][0]\n",
    "                    # positive_decoder_embeddings_2 = outputs.decoder_hidden_states[-1][1]\n",
    "                    # negative_decoder_embeddings_1 = outputs.decoder_hidden_states[-1][2]\n",
    "                    # negative_decoder_embeddings_2 = outputs.decoder_hidden_states[-1][3]\n",
    "\n",
    "                    # loss_1 = cosine_loss(positive_embeddings_1, negative_embeddings_1, contrastive)\n",
    "                    # loss_2 = cosine_loss(positive_embeddings_2, negative_embeddings_2, contrastive)\n",
    "                    # loss_1_decoder = cosine_loss(positive_decoder_embeddings_1, negative_decoder_embeddings_1, -1 * torch.ones(positive_decoder_embeddings_1.size(dim=0)).to(device))\n",
    "                    # loss_2_decoder = cosine_loss(positive_decoder_embeddings_2, negative_decoder_embeddings_2, -1 * torch.ones(positive_decoder_embeddings_2.size(dim=0)).to(device))\n",
    "                    # loss_cs = (loss_1 + loss_2) / 2\n",
    "                    # loss_cs_decoder = (loss_1_decoder + loss_2_decoder) / 2\n",
    "                    \n",
    "                    positive_embeddings = outputs.encoder_last_hidden_state[:divide_num,:,:max_encoder_token]\n",
    "                    negative_embeddings = outputs.encoder_last_hidden_state[divide_num:,:,:max_encoder_token]\n",
    "                    positive_embeddings = positive_embeddings.view(-1, max_encoder_token)\n",
    "                    negative_embeddings = negative_embeddings.view(-1, max_encoder_token)\n",
    "                    contrastive = -1 * torch.ones(positive_embeddings.size(dim=0)).to(device)\n",
    "\n",
    "                    model.config.max_position_embeddings\n",
    "\n",
    "                    loss_cs = cosine_embedding_loss(positive_embeddings, negative_embeddings, contrastive)\n",
    "                    \n",
    "                    output_probs_pos = output_probs[:divide_num,:,:]\n",
    "                    output_probs_pos = output_probs_pos.view(-1,\n",
    "                                                     model.config.vocab_size)\n",
    "                    output_probs_neg = output_probs[divide_num:,:,:]\n",
    "                    output_probs_neg = output_probs_neg.view(-1,\n",
    "                                                     model.config.vocab_size)\n",
    "                    \n",
    "    \n",
    "                    gt_logits = batch['labels'][:divide_num]\n",
    "                    gt_logits = gt_logits.view(-1)\n",
    "\n",
    "                    loss_nll, nll = label_smoothed_nll_loss(\n",
    "                        output_probs_pos, gt_logits, args.label_smoothing, ignore_index=tokenizer.pad_token_id)\n",
    "                    \n",
    "                    # (pos, neg, target, ignore_index=-100, ,device)\n",
    "                    target_one = torch.ones(gt_logits.shape[0]).to(device)\n",
    "                    loss_mr = margin_ranking_loss(output_probs_pos, output_probs_neg, \n",
    "                                                              gt_logits, target_one, ignore_index=tokenizer.pad_token_id)\n",
    "                    # print(f\"margin_ranking_loss: {loss_margin_ranking}\")\n",
    "                    loss = loss_nll + (args.alpha * loss_cs) + (args.alpha * loss_mr)\n",
    "                    # loss = loss_nll + (args.alpha * loss_cs)\n",
    "                    print(loss)\n",
    "                    break\n",
    "                    \n",
    "                else:\n",
    "                    output_probs = output_probs\n",
    "                    output_probs = output_probs.view(-1,\n",
    "                                                     model.config.vocab_size)\n",
    "                    \n",
    "    \n",
    "                    gt_logits = batch['labels']\n",
    "                    gt_logits = gt_logits.view(-1)\n",
    "                \n",
    "                    loss_nll, nll = label_smoothed_nll_loss(\n",
    "                        output_probs, gt_logits, args.label_smoothing, ignore_index=tokenizer.pad_token_id)\n",
    "    \n",
    "                    loss = loss_nll           \n",
    "                \n",
    "        break\n",
    "        acc_losses.append(loss.item())\n",
    "        loss_list.append(loss)\n",
    "        epoch_loss += loss.item()\n",
    "        loss = loss / args.gradient_accumulation_steps\n",
    "        # print(f\"loss_grad: {loss}\")\n",
    "        accelerator.backward(loss)\n",
    "        # break\n",
    "\n",
    "        if step % args.gradient_accumulation_steps == 0 or step == len(train_dataloader) - 1:\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "            progress_bar.update(1)\n",
    "            progress_bar.set_postfix(lr=lr_scheduler.get_last_lr()[\n",
    "                                     0], loss=np.mean(acc_losses[-50:]))\n",
    "            completed_steps += 1\n",
    "            train_loss_list.append(epoch_loss/len(batch))\n",
    "\n",
    "        if completed_steps >= args.max_train_steps:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 264, 1024])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.encoder_last_hidden_state[:2,:,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 264, 1024])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.encoder_last_hidden_state[2:,:,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(output_probs.shape[0] / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_probs_pos = output_probs[:2,:,:]\n",
    "output_probs_pos = output_probs_pos.view(-1,\n",
    "                                 model.config.vocab_size)\n",
    "output_probs_neg = output_probs[2:,:,:]\n",
    "output_probs_neg = output_probs_neg.view(-1,\n",
    "                                 model.config.vocab_size)\n",
    "gt_logits = batch['labels'][:2]\n",
    "gt_logits = gt_logits.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([80, 50265])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_probs_pos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([80, 50265])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_probs_neg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([96])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_pos = output_probs_pos[~gt_logits.eq(-100)]\n",
    "probs_neg = output_probs_neg[~gt_logits.eq(-100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt = gt_logits[~gt_logits.eq(-100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "if gt.dim() == probs_pos.dim() - 1:\n",
    "    gt = gt.unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "nll_pos = -probs_pos.gather(dim=-1, index=gt)\n",
    "nll_neg = -probs_neg.gather(dim=-1, index=gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "nll_sq_pos = nll_pos.squeeze(-1)\n",
    "nll_sq_neg = nll_neg.squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_one = torch.ones(nll_sq_pos.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "loss = nn.MarginRankingLoss()\n",
    "input1 = nll_sq_pos\n",
    "input2 = nll_sq_neg\n",
    "target = target_one.to(\"cuda:0\")\n",
    "output = loss(input1, input2, target)\n",
    "# output.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.3658, device='cuda:0', grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DTRdH7I6su3a",
    "outputId": "1bdae418-e213-4f73-a779-72e61fde2b04",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(outputs.encoder_last_hidden_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U0Ckx5K5su3b",
    "outputId": "6a0602b6-9e3d-442e-e3d9-486bb7f379a6",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0199,  0.0383,  0.0413,  ..., -0.0192,  0.0033, -0.0034],\n",
       "         [-0.1682, -0.0113,  0.1301,  ..., -0.0883, -0.0093, -0.1615],\n",
       "         [-0.0111, -0.4472,  0.0442,  ...,  0.0226, -0.0170, -0.2872],\n",
       "         ...,\n",
       "         [-0.0308, -0.2955, -0.3913,  ...,  0.0104, -0.0009, -0.0810],\n",
       "         [-0.0451, -0.4547, -0.5451,  ...,  0.1203, -0.0126,  0.1627],\n",
       "         [-0.0310, -0.0535, -0.3161,  ...,  0.0269, -0.0641,  0.1126]],\n",
       "\n",
       "        [[ 0.0211,  0.0319,  0.0484,  ..., -0.0260, -0.0024, -0.0104],\n",
       "         [-0.2227, -0.0779, -0.0718,  ...,  0.0067, -0.0177, -0.0376],\n",
       "         [-0.1187, -0.5692, -0.0248,  ..., -0.0780,  0.0284, -0.4738],\n",
       "         ...,\n",
       "         [-0.0440,  0.1978, -0.3247,  ..., -0.0017,  0.1312,  0.3230],\n",
       "         [-0.1271, -0.3494, -0.5145,  ...,  0.0051,  0.1007,  0.0965],\n",
       "         [-0.1246, -0.2684, -0.6091,  ...,  0.0990,  0.0489, -0.0175]]],\n",
       "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.encoder_last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fko7L0FCsu3c",
    "outputId": "31ce65fa-1a28-40a1-fcd3-917c401f3a3d",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "296"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.encoder_last_hidden_state.size(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WNyUX1MBsu3c",
    "outputId": "a4828cfc-fcea-454f-859f-93b32feb3ad1",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "torch.Size([48, 50266])\n"
     ]
    }
   ],
   "source": [
    "print(len(outputs.logits))\n",
    "print(outputs.logits[0].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DNn3RQYUsu3c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "cosine_loss = torch.nn.CosineEmbeddingLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j_VytNi5su3c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "loss_cs = cosine_loss(outputs.encoder_last_hidden_state[0], outputs.encoder_last_hidden_state[1], torch.ones(outputs.encoder_last_hidden_state.size(dim=1)).to(torch.device('cuda')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QBFlUpC5su3d",
    "outputId": "7192015b-7569-4fed-8a9c-79d4b2833650",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7458, device='cuda:0', grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_cs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      ""
     ]
    },
    "id": "Mh3MeO5hsu3d",
    "outputId": "9500b993-deb4-49f7-fdae-089ecb787d16",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10/04/2023 19:07:23 - INFO - __main__ - Loading Best Result is at epoch 4 for Testing\n",
      "loading configuration file ./output/1-bart-baseline-loss/best/config.json\n",
      "Model config BartConfig {\n",
      "  \"_name_or_path\": \"facebook/bart-large\",\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.1,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 12,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 16,\n",
      "  \"encoder_ffn_dim\": 4096,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 12,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_length\": 128,\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"min_length\": 1,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": false,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 128,\n",
      "      \"min_length\": 1,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_cnn\": {\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 142,\n",
      "      \"min_length\": 56,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_xsum\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 62,\n",
      "      \"min_length\": 11,\n",
      "      \"num_beams\": 6\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.33.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50266\n",
      "}\n",
      "\n",
      "loading file vocab.json\n",
      "loading file merges.txt\n",
      "loading file tokenizer.json\n",
      "loading file added_tokens.json\n",
      "loading file special_tokens_map.json\n",
      "loading file tokenizer_config.json\n",
      "loading weights file ./output/1-bart-baseline-loss/best/pytorch_model.bin\n",
      "Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"max_length\": 128,\n",
      "  \"min_length\": 1,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.33.3\"\n",
      "}\n",
      "\n",
      "All model checkpoint weights were used when initializing BartForConditionalGeneration.\n",
      "\n",
      "All the weights of BartForConditionalGeneration were initialized from the model checkpoint at ./output/1-bart-baseline-loss/best.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BartForConditionalGeneration for predictions without further training.\n",
      "loading configuration file ./output/1-bart-baseline-loss/best/generation_config.json\n",
      "Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"max_length\": 128,\n",
      "  \"min_length\": 1,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.33.3\"\n",
      "}\n",
      "\n",
      "10/04/2023 19:07:29 - INFO - __main__ - Collecting Testing Result...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"max_length\": 128,\n",
      "  \"min_length\": 1,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.33.3\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"max_length\": 128,\n",
      "  \"min_length\": 1,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.33.3\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"max_length\": 128,\n",
      "  \"min_length\": 1,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.33.3\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"max_length\": 128,\n",
      "  \"min_length\": 1,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.33.3\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"max_length\": 128,\n",
      "  \"min_length\": 1,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.33.3\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"max_length\": 128,\n",
      "  \"min_length\": 1,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.33.3\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"max_length\": 128,\n",
      "  \"min_length\": 1,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.33.3\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"max_length\": 128,\n",
      "  \"min_length\": 1,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.33.3\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"max_length\": 128,\n",
      "  \"min_length\": 1,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.33.3\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"max_length\": 128,\n",
      "  \"min_length\": 1,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.33.3\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"max_length\": 128,\n",
      "  \"min_length\": 1,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.33.3\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"max_length\": 128,\n",
      "  \"min_length\": 1,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.33.3\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"max_length\": 128,\n",
      "  \"min_length\": 1,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.33.3\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"max_length\": 128,\n",
      "  \"min_length\": 1,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.33.3\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"max_length\": 128,\n",
      "  \"min_length\": 1,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.33.3\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"max_length\": 128,\n",
      "  \"min_length\": 1,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.33.3\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"max_length\": 128,\n",
      "  \"min_length\": 1,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.33.3\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"max_length\": 128,\n",
      "  \"min_length\": 1,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.33.3\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"max_length\": 128,\n",
      "  \"min_length\": 1,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.33.3\"\n",
      "}\n",
      "\n",
      "10/04/2023 19:08:05 - INFO - __main__ - \n",
      "10/04/2023 19:08:05 - INFO - __main__ - ROUGE score on test set\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic of Summary: communication method. Length of Summary: 27. Dialogue: # Person1 # : Ms. Dawson , I need you to take a dictation for me . # Person2 # : Yes , sir ... # Person1 # : This should go out as an intra-office memorandum to all employees by this afternoon . Are you ready ? # Person2 # : Yes , sir . Go ahead . # Person1 # : Attention all staff ... Effective immediately , all office [TAG]communications[TAG] are restricted to email correspondence and official memos . The use of Instant Message programs by employees during working hours is strictly prohibited . # Person2 # : Sir , does this apply to intra-office [TAG]communications[TAG] only ? Or will it also restrict external [TAG]communications[TAG] ? # Person1 # : It should apply to all [TAG]communications[TAG] , not only in this office between employees , but also any outside [TAG]communications[TAG] . # Person2 # : But sir , many employees use Instant Messaging to communicate with their clients . # Person1 # : They will just have to change their [TAG]communication[TAG] [TAG]methods[TAG] . I do n't want any - one using Instant Messaging in this office . It wastes too much time ! Now , please continue with the memo . Where were we ? # Person2 # : This applies to internal and external [TAG]communications[TAG] . # Person1 # : Yes . Any employee who persists in using Instant Messaging will first receive a warning and be placed on probation . At second offense , the employee will face termination . Any questions regarding this new policy may be directed to department heads . # Person2 # : Is that all ? # Person1 # : Yes . Please get this memo typed up and distributed to all employees before 4 pm .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10/04/2023 19:08:05 - INFO - root - \n",
      "10/04/2023 19:08:05 - INFO - root - \trouge-1:\tP: 37.12\tR: 47.88\tF1: 40.73\n",
      "10/04/2023 19:08:05 - INFO - root - \trouge-2:\tP: 13.30\tR: 17.25\tF1: 14.64\n",
      "10/04/2023 19:08:05 - INFO - root - \trouge-l:\tP: 35.01\tR: 43.23\tF1: 37.96\n",
      "10/04/2023 19:08:05 - INFO - root - \n",
      "10/04/2023 19:08:05 - INFO - __main__ - \n"
     ]
    }
   ],
   "source": [
    "# =  =  =  =  =  =  =  =  =  =  =  =  =  =  =  = Test =  =  =  =  =  =  =  =  =  =  =  =  =  =  =  =  =  =  =\n",
    "# load best model\n",
    "logger.info(\"Loading Best Result is at epoch {} for Testing\".format(best_epoch))\n",
    "\n",
    "unwrapped_model = accelerator.unwrap_model(model)\n",
    "config          = config.from_pretrained(args.output_dir+'/best')\n",
    "tokenizer       = tokenizer.from_pretrained(args.output_dir+'/best', config=config)\n",
    "unwrapped_model = unwrapped_model.from_pretrained(args.output_dir+'/best', config=config)\n",
    "model           = accelerator.prepare(unwrapped_model)\n",
    "\n",
    "if args.model_type == 'bart' or args.model_type == 't5':\n",
    "    task_specific_params = model.config.task_specific_params\n",
    "    params = task_specific_params.get('summarization', {})\n",
    "    params['min_length'] = args.min_target_length\n",
    "    params['max_length'] = args.max_target_length\n",
    "    params['length_penalty'] = args.length_penalty\n",
    "    params['num_beams'] = args.num_beams\n",
    "    model.config.update(params)\n",
    "else:\n",
    "    raise ValueError('{} model type not implemented'.format(args.model_type))\n",
    "\n",
    "# start Test\n",
    "logger.info(\"Collecting Testing Result...\")\n",
    "model.eval()\n",
    "\n",
    "test_predict     = []\n",
    "test_groundtruth = []\n",
    "for step, batch in enumerate(tqdm(test_dataloader, leave=False)):\n",
    "    with torch.no_grad():\n",
    "        generated_tokens = accelerator.unwrap_model(model).generate(\n",
    "            batch[\"input_ids\"],\n",
    "            attention_mask=batch[\"attention_mask\"],\n",
    "        )\n",
    "\n",
    "        generated_tokens = accelerator.pad_across_processes(\n",
    "            generated_tokens, dim=1, pad_index=tokenizer.pad_token_id\n",
    "        )\n",
    "        labels = batch[\"labels\"]\n",
    "\n",
    "        if not args.pad_to_max_length:\n",
    "            # If we did not pad to max length, we need to pad the labels too\n",
    "            labels = accelerator.pad_across_processes(batch[\"labels\"], dim=1, pad_index=tokenizer.pad_token_id)\n",
    "\n",
    "        generated_tokens = accelerator.gather(generated_tokens).cpu().numpy()\n",
    "        labels = accelerator.gather(labels).cpu().numpy()\n",
    "\n",
    "        if args.ignore_pad_token_for_loss:\n",
    "            # Replace -100 in the labels as we can't decode them.\n",
    "            labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "        if isinstance(generated_tokens, tuple):\n",
    "            generated_tokens = generated_tokens[0]\n",
    "\n",
    "        decoded_preds  = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n",
    "        decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "        decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
    "\n",
    "        decoded_preds  = [' '.join(sent.split('\\n')) for sent in decoded_preds]\n",
    "        decoded_labels = [' '.join(sent.split('\\n')) for sent in decoded_labels]\n",
    "\n",
    "        test_predict.extend(decoded_preds)\n",
    "        test_groundtruth.extend(decoded_labels)\n",
    "\n",
    "print(raw_datasets['test']['dialogue'][0])\n",
    "\n",
    "if args.len_output == 'real':\n",
    "    new_test_predict = []\n",
    "    for sample in test_predict:\n",
    "        try:\n",
    "            gen_sum = sample.split('Summary: ')[2]\n",
    "            new_test_predict.append(gen_sum)\n",
    "        except:\n",
    "            new_test_predict.append(sample)\n",
    "    test_predict = new_test_predict\n",
    "\n",
    "logger.info(\"\")\n",
    "logger.info(\"ROUGE score on test set\")\n",
    "test_scores = py_rouge_scores(test_predict, test_groundtruth)\n",
    "logger.info(\"\")\n",
    "\n",
    "\n",
    "# Save generated summaries\n",
    "if args.len_input == 'predict':\n",
    "    os.makedirs(args.output_dir+'/predict_gen_samples', exist_ok=True)\n",
    "else:\n",
    "    os.makedirs(args.output_dir+'/gen_samples', exist_ok=True)\n",
    "\n",
    "for i in range(len(test_predict)):\n",
    "    test_id        = raw_datasets['test']['id'][i]\n",
    "    test_dialogue  = raw_datasets['test']['dialogue'][i]\n",
    "    test_summary   = raw_datasets['test']['summary'][i]\n",
    "    test_predict_s = test_predict[i]\n",
    "\n",
    "    if args.len_input == 'predict':\n",
    "        with open(args.output_dir+'/predict_gen_samples/'+str(test_id)+'.txt', 'w') as f:\n",
    "            test_dialogue = test_dialogue.encode('ascii', 'ignore').decode('ascii')\n",
    "            f.write(test_dialogue)\n",
    "            f.write('\\n\\n')\n",
    "            f.write('Golden Summary:\\n')\n",
    "            test_summary = test_summary.encode('ascii', 'ignore').decode('ascii')\n",
    "            f.write(test_summary)\n",
    "            f.write('\\n\\n')\n",
    "            f.write('Generate Summary:\\n')\n",
    "            test_predict_s = test_predict_s.encode('ascii', 'ignore').decode('ascii')\n",
    "            f.write(test_predict_s)\n",
    "    else:\n",
    "        with open(args.output_dir+'/gen_samples/'+str(test_id)+'.txt', 'w') as f:\n",
    "            test_dialogue = test_dialogue.encode('ascii', 'ignore').decode('ascii')\n",
    "            f.write(test_dialogue)\n",
    "            f.write('\\n\\n')\n",
    "            f.write('Golden Summary:\\n')\n",
    "            test_summary = test_summary.encode('ascii', 'ignore').decode('ascii')\n",
    "            f.write(test_summary)\n",
    "            f.write('\\n\\n')\n",
    "            f.write('Generate Summary:\\n')\n",
    "            test_predict_s = test_predict_s.encode('ascii', 'ignore').decode('ascii')\n",
    "            f.write(test_predict_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dvNEVEiCsu3e"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nuPFvbUWsu3e"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "13bb8c4b9a154bb99c4d38cd2edb631c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "14052c5abfad4231a0d4c8d0e0395a01": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "24272444846441638d4836fd835562dc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_78f6c1bca77640ca92bd87d5995fced5",
       "IPY_MODEL_81669ba2443a489cb535c508333dc974",
       "IPY_MODEL_47ddb2c2d8fa4c278c9d514ace68341f"
      ],
      "layout": "IPY_MODEL_b842e08bc1ca45ee99a868d1dfa4d0db"
     }
    },
    "31409e259c8b4ee7899035ea4ba3f140": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "326356876bd540778d188c41673e04f5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "35f50d433dc14aa28cf0f5a039f7cb87": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "368a820467ad4f4d8198932125f0d357": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3bad8094e9124ab391d945edf4ccca2f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4616558f0ebd466babad0202bc55824d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "47ddb2c2d8fa4c278c9d514ace68341f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_932e4629e7f340c2a5b64d095c46bf4d",
      "placeholder": "​",
      "style": "IPY_MODEL_a26c7dc74d71494787fd32d560594b38",
      "value": " 500/500 [00:01&lt;00:00, 317.13 examples/s]"
     }
    },
    "542a00a050384f5f8f3f7354eb527336": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5a2947306125452c8c25c12e54dc6656": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "78f6c1bca77640ca92bd87d5995fced5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4616558f0ebd466babad0202bc55824d",
      "placeholder": "​",
      "style": "IPY_MODEL_9a4ed651601f4a29b763eed10afafc16",
      "value": "Running tokenizer on dataset: 100%"
     }
    },
    "7f1272db213a4121ae95b5e41061d964": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e69f5057741b46dba3ebb186ef85c6db",
      "max": 1500,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_14052c5abfad4231a0d4c8d0e0395a01",
      "value": 1500
     }
    },
    "81669ba2443a489cb535c508333dc974": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_368a820467ad4f4d8198932125f0d357",
      "max": 500,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f5ece15e08e44905a09d9a2e988a4be4",
      "value": 500
     }
    },
    "852ba2b2a4fd4bbe80a2ecd9c9f6b5fb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b1a15a93c5e746888806f8dd19cf6889",
      "placeholder": "​",
      "style": "IPY_MODEL_35f50d433dc14aa28cf0f5a039f7cb87",
      "value": "Running tokenizer on dataset: 100%"
     }
    },
    "90b25ecb208546f9938652c360ef7a5e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_852ba2b2a4fd4bbe80a2ecd9c9f6b5fb",
       "IPY_MODEL_7f1272db213a4121ae95b5e41061d964",
       "IPY_MODEL_a3ad3e93702041d89b6f505ec6d37411"
      ],
      "layout": "IPY_MODEL_ffcb842d99954cdcaa8fb78e8e3b2215"
     }
    },
    "932e4629e7f340c2a5b64d095c46bf4d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9a4ed651601f4a29b763eed10afafc16": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9c182b108efa471994186923f10871a8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a26c7dc74d71494787fd32d560594b38": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a3ad3e93702041d89b6f505ec6d37411": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3bad8094e9124ab391d945edf4ccca2f",
      "placeholder": "​",
      "style": "IPY_MODEL_31409e259c8b4ee7899035ea4ba3f140",
      "value": " 1500/1500 [00:03&lt;00:00, 414.56 examples/s]"
     }
    },
    "a91a8c5870234ab3bdd0132addb34a20": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b1a15a93c5e746888806f8dd19cf6889": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b842e08bc1ca45ee99a868d1dfa4d0db": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c34934bec45646a8b2ac76c60dc124d5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d0098c03b82d48c9acdc684fbbf54567": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fa32d34f467944f2aaf4a13fdf7a0cf2",
       "IPY_MODEL_e3bc145889c94fc3974e88e46863db89",
       "IPY_MODEL_ddbc6421b4cf487d92cc53fb0ae6f634"
      ],
      "layout": "IPY_MODEL_13bb8c4b9a154bb99c4d38cd2edb631c"
     }
    },
    "ddbc6421b4cf487d92cc53fb0ae6f634": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9c182b108efa471994186923f10871a8",
      "placeholder": "​",
      "style": "IPY_MODEL_c34934bec45646a8b2ac76c60dc124d5",
      "value": " 12460/12460 [00:20&lt;00:00, 564.66 examples/s]"
     }
    },
    "e3bc145889c94fc3974e88e46863db89": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_542a00a050384f5f8f3f7354eb527336",
      "max": 12460,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a91a8c5870234ab3bdd0132addb34a20",
      "value": 12460
     }
    },
    "e69f5057741b46dba3ebb186ef85c6db": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f5ece15e08e44905a09d9a2e988a4be4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "fa32d34f467944f2aaf4a13fdf7a0cf2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5a2947306125452c8c25c12e54dc6656",
      "placeholder": "​",
      "style": "IPY_MODEL_326356876bd540778d188c41673e04f5",
      "value": "Running tokenizer on dataset: 100%"
     }
    },
    "ffcb842d99954cdcaa8fb78e8e3b2215": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
