{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4538cce7-c5b6-4824-a59a-152a6455d74d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import BartTokenizer, BartForConditionalGeneration\n",
    "\n",
    "# Assuming you have a dataset with source documents, positive summaries, and negative summaries\n",
    "# Define your dataset class\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "# Define your custom DataCollator\n",
    "class CustomDataCollator:\n",
    "    def __init__(self, tokenizer, model):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.model = model\n",
    "\n",
    "    def __call__(self, examples):\n",
    "        positive_documents = [example['positive_document'] for example in examples]\n",
    "        negative_documents = [example['negative_document'] for example in examples]\n",
    "        source_summaries = [example['source_summary'] for example in examples]\n",
    "\n",
    "        # Tokenize and create input tensors\n",
    "        inputs = self.tokenizer(\n",
    "            positive_documents,\n",
    "            # negative_summaries,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=512  # Adjust as needed\n",
    "        )\n",
    "        \n",
    "        # Tokenize and create input tensors\n",
    "        negative_inputs = self.tokenizer(\n",
    "            negative_documents,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=512  # Adjust as needed\n",
    "        )\n",
    "        \n",
    "        with tokenizer.as_target_tokenizer():\n",
    "            labels = self.tokenizer(\n",
    "                source_summaries,\n",
    "                return_tensors=\"pt\",\n",
    "                padding=True,\n",
    "                truncation=True,\n",
    "                max_length=512  # Adjust as needed\n",
    "            )\n",
    "        \n",
    "        inputs[\"negative_input_ids\"] = negative_inputs[\"input_ids\"]\n",
    "        inputs[\"negative_attention_mask\"] = negative_inputs[\"attention_mask\"]\n",
    "        inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "\n",
    "        return inputs\n",
    "\n",
    "# Load BART model and tokenizer\n",
    "model_name = \"facebook/bart-large-cnn\"\n",
    "tokenizer = BartTokenizer.from_pretrained(model_name)\n",
    "model = BartForConditionalGeneration .from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9f7a5db4-3cfc-488c-b459-b7c0766cee1f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[    0, 22173,  1215, 43017,  1215,   246,     2],\n",
      "        [    0, 22173,  1215, 43017,  1215,   306,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1]]), 'negative_input_ids': tensor([[    0, 33407,  1215, 43017,  1215,   246,  1215, 17747,  1215, 48600,\n",
      "             2],\n",
      "        [    0, 33407,  1215, 43017,  1215,   306,  1215, 17747,  1215, 48600,\n",
      "             2]]), 'negative_attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'labels': tensor([[    0, 17747,  1215, 48600,  1215,   246,    19,    10,     2,     1,\n",
      "             1,     1],\n",
      "        [    0, 17747,  1215, 48600,  1215,   306,    19,    10, 30581,  3923,\n",
      "         12346,     2]])}\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "BartForConditionalGeneration.forward() got an unexpected keyword argument 'negative_input_ids'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[93], line 25\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(inputs)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# break\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(outputs\u001b[38;5;241m.\u001b[39mencoder_last_hidden_state\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "\u001b[0;31mTypeError\u001b[0m: BartForConditionalGeneration.forward() got an unexpected keyword argument 'negative_input_ids'"
     ]
    }
   ],
   "source": [
    "# Load your dataset and create DataLoader\n",
    "data = [{'positive_document': 'positive_document_1', 'negative_document': 'negative_document_1_source_summary', 'source_summary': 'source_summary_1 with a Hugging Face datasets'},\n",
    "       {'positive_document': 'positive_document_2', 'negative_document': 'negative_document_2_source_summary', 'source_summary': 'source_summary_2 with a Hugging '},\n",
    "       {'positive_document': 'positive_document_3', 'negative_document': 'negative_document_3_source_summary', 'source_summary': 'source_summary_3 with a'},\n",
    "       {'positive_document': 'positive_document_4', 'negative_document': 'negative_document_4_source_summary', 'source_summary': 'source_summary_4 with a Hugging Face'}]\n",
    "custom_dataset = CustomDataset(data)\n",
    "custom_data_collator = CustomDataCollator(tokenizer, model)\n",
    "dataloader = DataLoader(custom_dataset, batch_size=2, collate_fn=custom_data_collator, shuffle=True)\n",
    "\n",
    "# Define your contrastive loss function\n",
    "contrastive_loss = torch.nn.TripletMarginLoss(margin=1.0)\n",
    "\n",
    "# Training loop\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "epochs = 3\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for batch in dataloader:\n",
    "        inputs = batch\n",
    "        print(inputs)\n",
    "        # break\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(**inputs, output_hidden_states=True)\n",
    "        \n",
    "        print(outputs.encoder_last_hidden_state.shape)\n",
    "        break\n",
    "        # Extract embeddings\n",
    "        source_embeddings = outputs.encoder_last_hidden_state[0]\n",
    "        positive_embeddings = outputs.encoder_last_hidden_state[1]\n",
    "        negative_embeddings = outputs.encoder_last_hidden_state[2]\n",
    "\n",
    "        # Compute contrastive loss\n",
    "        loss = contrastive_loss(source_embeddings, positive_embeddings, negative_embeddings)\n",
    "        print(loss)\n",
    "\n",
    "        # Backpropagation and optimization step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "514dc41c-d626-4a39-b914-74a4c794fd97",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 7])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "56cc4c7a-867e-48c0-b939-17828cc485dd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([11])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs['negative_input_ids'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "cb02817f-e98b-46af-8497-0b689e8c3258",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([11])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs['negative_input_ids'][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "71082c5c-63b0-42ff-8144-a49a72b35dd7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    0, 22173,  1215, 43017,  1215,   134,     2])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs['input_ids'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "38263953-0771-4500-86de-46a16b0f98ce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s>positive_document_1</s>'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(inputs['input_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f7e84681-432e-474a-96cd-c42d2ef7b4fa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s>positive_document_4</s>'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(inputs['input_ids'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8323ff6e-7257-4c2d-9f5f-06ccd9e7bff7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1d92c5-39c2-4164-9463-bfa26fbb1143",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
