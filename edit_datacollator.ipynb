{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9814be8f-7419-4a2b-97a9-b079578729b0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5dba7a568b7450fa06aa063240b1f42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e00ae74e85d4131b4b3f65d27b66500",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b397aa57d1c4e7791924d5d0cafac27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d58702b8ac847269abd7838592a5db5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ea3247ce9f44aa0bf48f5a1c19315d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.63k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47a01d57bc084f84a99a9e312db861c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/1.02G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import BartTokenizer, BartForConditionalGeneration\n",
    "\n",
    "# Load BART model and tokenizer\n",
    "model_name = \"facebook/bart-large\"\n",
    "tokenizer = BartTokenizer.from_pretrained(model_name)\n",
    "model = BartForConditionalGeneration .from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe53b896-0314-4c7b-8893-b3ece27cc2dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4538cce7-c5b6-4824-a59a-152a6455d74d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assuming you have a dataset with source documents, positive summaries, and negative summaries\n",
    "# Define your dataset class\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "# Define your custom DataCollator\n",
    "class CustomDataCollator:\n",
    "    def __init__(self, tokenizer, model):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.model = model\n",
    "\n",
    "    def __call__(self, examples):\n",
    "        positive_documents = [example['positive_document'] for example in examples]\n",
    "        negative_documents = [example['negative_document'] for example in examples]\n",
    "        source_summaries = [example['source_summary'] for example in examples]\n",
    "\n",
    "        # Tokenize and create input tensors\n",
    "        inputs = self.tokenizer(\n",
    "            positive_documents,\n",
    "            # negative_summaries,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=512  # Adjust as needed\n",
    "        )\n",
    "        \n",
    "        # Tokenize and create input tensors\n",
    "        negative_inputs = self.tokenizer(\n",
    "            negative_documents,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=512  # Adjust as needed\n",
    "        )\n",
    "        \n",
    "        with tokenizer.as_target_tokenizer():\n",
    "            labels = self.tokenizer(\n",
    "                source_summaries,\n",
    "                return_tensors=\"pt\",\n",
    "                padding=True,\n",
    "                truncation=True,\n",
    "                max_length=512  # Adjust as needed\n",
    "            )\n",
    "            \n",
    "        # inputs[\"input_ids\"] = tokenizer.pad\n",
    "        # negative_inputs[\"input_ids\"] = tokenizer.pad\n",
    "        \n",
    "        batch = tokenizer.pad(encoded_inputs={\"input_ids\": inputs[\"input_ids\"].squeeze().tolist() + negative_inputs[\"input_ids\"].squeeze().tolist()}, padding=True, return_tensors='pt')\n",
    "        # batch[\"decoder_input_ids\"] = torch.stack((inputs[\"labels\"], inputs[\"labels\"]))\n",
    "        # batch[\"decoder_attention_mask\"] = torch.stack((inputs[\"labels\"], inputs[\"decoder_attention_mask\"]))\n",
    "        batch[\"decoder_input_ids\"] = tokenizer.pad(encoded_inputs={\"input_ids\": labels[\"input_ids\"].squeeze().tolist()+labels[\"input_ids\"].squeeze().tolist()}, padding=False, return_tensors='pt')[\"input_ids\"]\n",
    "        labels[\"input_ids\"] = [[(l if l != tokenizer.pad_token_id else -100) for l in label] for label in labels[\"input_ids\"]]\n",
    "        batch[\"labels\"] =  tokenizer.pad(encoded_inputs={\"input_ids\": labels[\"input_ids\"]+labels[\"input_ids\"]}, padding=True, return_tensors='pt')[\"input_ids\"]\n",
    "\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12b588cb-36a7-48ce-ada5-25493b9e720a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your dataset and create DataLoader\n",
    "data = [{'positive_document': 'positive_document_1 with a Hugging ', 'negative_document': 'negative_document_1_source_summary', 'source_summary': 'source_summary_1 with a Hugging Face datasets'},\n",
    "       {'positive_document': 'positive_document_2 with a Hugging Face datasets', 'negative_document': 'negative_document_2_source_summary', 'source_summary': 'source_summary_2 with a Hugging '},\n",
    "       {'positive_document': 'positive_document_3 with a Hugging Face', 'negative_document': 'negative_document_3_source_summary', 'source_summary': 'source_summary_3 with a'},\n",
    "       {'positive_document': 'positive_document_4 with a', 'negative_document': 'negative_document_4_source_summary', 'source_summary': 'source_summary_4 with a Hugging Face'}]\n",
    "custom_dataset = CustomDataset(data)\n",
    "custom_data_collator = CustomDataCollator(tokenizer, model)\n",
    "dataloader = DataLoader(custom_dataset, batch_size=2, collate_fn=custom_data_collator, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ee41303-9de5-4e0d-a268-05e82ae5367b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 13])\n",
      "----------------------------------------------------------------------------------------------------\n",
      "torch.Size([4, 12])\n",
      "====================================================================================================\n",
      "torch.Size([4, 13])\n",
      "----------------------------------------------------------------------------------------------------\n",
      "torch.Size([4, 13])\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "epochs = 2\n",
    "for epoch in range(epochs):\n",
    "    for batch in dataloader:\n",
    "        print(batch['input_ids'].shape)\n",
    "        print('-'*100)\n",
    "        print(batch['decoder_input_ids'].shape)\n",
    "        print('='*100)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f7a5db4-3cfc-488c-b459-b7c0766cee1f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 11, 1024])\n",
      "torch.Size([11, 1024])\n",
      "torch.Size([11, 1024])\n",
      "torch.Size([11, 1024])\n",
      "torch.Size([11, 1024])\n",
      "loss 1:  tensor(2.0591e-07, grad_fn=<MeanBackward0>)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "loss 2:  tensor(2.0591e-07, grad_fn=<MeanBackward0>)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "loss:  tensor(2.0591e-07, grad_fn=<DivBackward0>)\n",
      "====================================================================================================\n",
      "torch.Size([4, 11, 1024])\n",
      "torch.Size([11, 1024])\n",
      "torch.Size([11, 1024])\n",
      "torch.Size([11, 1024])\n",
      "torch.Size([11, 1024])\n",
      "loss 1:  tensor(2.8014e-06, grad_fn=<MeanBackward0>)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "loss 2:  tensor(2.8014e-06, grad_fn=<MeanBackward0>)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "loss:  tensor(2.8014e-06, grad_fn=<DivBackward0>)\n",
      "====================================================================================================\n",
      "torch.Size([4, 11, 1024])\n",
      "torch.Size([11, 1024])\n",
      "torch.Size([11, 1024])\n",
      "torch.Size([11, 1024])\n",
      "torch.Size([11, 1024])\n",
      "loss 1:  tensor(-2.7093e-08, grad_fn=<MeanBackward0>)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "loss 2:  tensor(-2.7093e-08, grad_fn=<MeanBackward0>)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "loss:  tensor(-2.7093e-08, grad_fn=<DivBackward0>)\n",
      "====================================================================================================\n",
      "torch.Size([4, 11, 1024])\n",
      "torch.Size([11, 1024])\n",
      "torch.Size([11, 1024])\n",
      "torch.Size([11, 1024])\n",
      "torch.Size([11, 1024])\n",
      "loss 1:  tensor(1.0837e-08, grad_fn=<MeanBackward0>)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "loss 2:  tensor(1.0837e-08, grad_fn=<MeanBackward0>)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "loss:  tensor(1.0837e-08, grad_fn=<DivBackward0>)\n",
      "====================================================================================================\n",
      "torch.Size([4, 11, 1024])\n",
      "torch.Size([11, 1024])\n",
      "torch.Size([11, 1024])\n",
      "torch.Size([11, 1024])\n",
      "torch.Size([11, 1024])\n",
      "loss 1:  tensor(-7.5860e-08, grad_fn=<MeanBackward0>)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "loss 2:  tensor(-7.5860e-08, grad_fn=<MeanBackward0>)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "loss:  tensor(-7.5860e-08, grad_fn=<DivBackward0>)\n",
      "====================================================================================================\n",
      "torch.Size([4, 11, 1024])\n",
      "torch.Size([11, 1024])\n",
      "torch.Size([11, 1024])\n",
      "torch.Size([11, 1024])\n",
      "torch.Size([11, 1024])\n",
      "loss 1:  tensor(0., grad_fn=<MeanBackward0>)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "loss 2:  tensor(0., grad_fn=<MeanBackward0>)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "loss:  tensor(0., grad_fn=<DivBackward0>)\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Define your contrastive loss function\n",
    "# contrastive_loss = torch.nn.TripletMarginLoss(margin=1.0)\n",
    "cosine_loss = torch.nn.CosineEmbeddingLoss()\n",
    "\n",
    "# Training loop\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "epochs = 3\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for batch in dataloader:\n",
    "        inputs = batch\n",
    "        # print(inputs)\n",
    "        # break\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(**inputs, output_hidden_states=True)\n",
    "        \n",
    "        print(outputs.encoder_last_hidden_state.shape)\n",
    "        # break\n",
    "        # Extract embeddings\n",
    "        positive_embeddings_1 = outputs.encoder_last_hidden_state[0]\n",
    "        print(positive_embeddings_1.shape)\n",
    "        positive_embeddings_2 = outputs.encoder_last_hidden_state[1]\n",
    "        print(positive_embeddings_2.shape)\n",
    "        negative_embeddings_1 = outputs.encoder_last_hidden_state[2]\n",
    "        print(negative_embeddings_1.shape)\n",
    "        negative_embeddings_2 = outputs.encoder_last_hidden_state[3]\n",
    "        print(negative_embeddings_2.shape)\n",
    "        # break\n",
    "        # Compute contrastive loss\n",
    "        loss_1 = cosine_loss(positive_embeddings_1, negative_embeddings_1, torch.ones(positive_embeddings_1.size(dim=0)))\n",
    "        loss_2 = cosine_loss(positive_embeddings_1, negative_embeddings_1, torch.ones(positive_embeddings_2.size(dim=0)))\n",
    "        loss = (loss_1 + loss_2) / 2\n",
    "        print(\"loss 1: \", loss_1)\n",
    "        print('-'*100)\n",
    "        print(\"loss 2: \", loss_2)\n",
    "        print('-'*100)\n",
    "        print(\"loss: \", loss)\n",
    "        print('='*100)\n",
    "        # break\n",
    "\n",
    "        # Backpropagation and optimization step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6ba79210-3e1e-4dc4-80ca-9a0bb8a6c7ac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_embeddings_1.size(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "615c4a1e-6a45-46e1-b576-f2a91651f5ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Tokenize and create input tensors\n",
    "inputs = tokenizer(\n",
    "    [data[0]['positive_document'], data[1]['positive_document']],\n",
    "    # negative_summaries,\n",
    "    return_tensors=\"pt\",\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    max_length=512  # Adjust as needed\n",
    ")\n",
    "\n",
    "# Tokenize and create input tensors\n",
    "negative_inputs = tokenizer(\n",
    "    [data[0]['negative_document'], data[1]['negative_document']],\n",
    "    return_tensors=\"pt\",\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    max_length=512  # Adjust as needed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "72738e33-f2ad-48de-9da4-6aa68249902b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 22173, 1215, 43017, 1215, 134, 2],\n",
       " [0, 22173, 1215, 43017, 1215, 176, 2],\n",
       " [0, 33407, 1215, 43017, 1215, 134, 1215, 17747, 1215, 48600, 2],\n",
       " [0, 33407, 1215, 43017, 1215, 176, 1215, 17747, 1215, 48600, 2]]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[\"input_ids\"].squeeze().tolist() + negative_inputs[\"input_ids\"].squeeze().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "3cec2f72-c4df-409b-aec8-af27cef3e9b4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 33407, 1215, 43017, 1215, 134, 1215, 17747, 1215, 48600, 2],\n",
       " [0, 33407, 1215, 43017, 1215, 176, 1215, 17747, 1215, 48600, 2]]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_inputs[\"input_ids\"].squeeze().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "97f1293c-c7fe-40cb-8700-18160717b645",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "c = tokenizer.truncate_sequences(inputs[\"input_ids\"], negative_inputs[\"input_ids\"], truncation_strategy='longest_first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "165f3cc8-2773-4e2b-abfb-cd5bd493c20e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[    0, 22173,  1215, 43017,  1215,   134,     2],\n",
       "         [    0, 22173,  1215, 43017,  1215,   176,     2]]),\n",
       " tensor([[    0, 33407,  1215, 43017,  1215,   134,  1215, 17747,  1215, 48600,\n",
       "              2],\n",
       "         [    0, 33407,  1215, 43017,  1215,   176,  1215, 17747,  1215, 48600,\n",
       "              2]]),\n",
       " [])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "88f79893-e4d7-4384-b521-43e9519f6755",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "d = inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "3f6e277b-2136-4791-af05-1b36df4c3277",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    0, 22173,  1215, 43017,  1215,   134,     2],\n",
       "        [    0, 22173,  1215, 43017,  1215,   176,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "4e8bb35b-8cb6-4180-9b33-801f3efbae1f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[0, 22173, 1215, 43017, 1215, 134, 2],\n",
       "  [0, 33407, 1215, 43017, 1215, 134, 1215, 17747, 1215, 48600, 2]]}"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\"input_ids\": [inputs[\"input_ids\"].squeeze().tolist()[0], negative_inputs[\"input_ids\"].squeeze().tolist()[0]]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "5be06343-48a9-4b2c-86a0-5df76a8e0a67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch = tokenizer.pad(encoded_inputs={\"input_ids\": inputs[\"input_ids\"].squeeze().tolist() + negative_inputs[\"input_ids\"].squeeze().tolist()}, padding=True, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "76c884e8-2681-4500-b682-274cd647cd62",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    0, 22173,  1215, 43017,  1215,   134,     2,     1,     1,     1,\n",
       "             1],\n",
       "        [    0, 22173,  1215, 43017,  1215,   176,     2,     1,     1,     1,\n",
       "             1],\n",
       "        [    0, 33407,  1215, 43017,  1215,   134,  1215, 17747,  1215, 48600,\n",
       "             2],\n",
       "        [    0, 33407,  1215, 43017,  1215,   176,  1215, 17747,  1215, 48600,\n",
       "             2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6c18bb0c-1a6a-4697-a9c4-75181f11c7cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch = tokenizer.pad(encoded_inputs={\"input_ids\": [inputs[\"input_ids\"].squeeze().tolist(), negative_inputs[\"input_ids\"].squeeze().tolist()]}, padding=True, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252b947f-f749-4c16-ab9e-5e63dcee3234",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "514dc41c-d626-4a39-b914-74a4c794fd97",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 7])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "56cc4c7a-867e-48c0-b939-17828cc485dd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([11])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs['negative_input_ids'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "cb02817f-e98b-46af-8497-0b689e8c3258",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([11])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs['negative_input_ids'][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "71082c5c-63b0-42ff-8144-a49a72b35dd7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    0, 22173,  1215, 43017,  1215,   134,     2])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs['input_ids'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "38263953-0771-4500-86de-46a16b0f98ce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s>positive_document_1</s>'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(inputs['input_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f7e84681-432e-474a-96cd-c42d2ef7b4fa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s>positive_document_4</s>'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(inputs['input_ids'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8323ff6e-7257-4c2d-9f5f-06ccd9e7bff7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1d92c5-39c2-4164-9463-bfa26fbb1143",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
